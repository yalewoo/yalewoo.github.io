<!DOCTYPE html>
<html>
	<head>
		<title>
			Andrew Ng机器学习课程笔记7——支持向量机（SVM）  |  雅乐网		</title>
		
		<meta charset="UTF-8" />
		<meta name="renderer" content="webkit">
		<link rel="stylesheet" href="http://www.yalewoo.com/wp-content/themes/YLW3_lite/style.css" type="text/css" />
		<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://www.yalewoo.com/feed" />


				
		
<!-- All in One SEO Pack 2.3.12.1 by Michael Torbert of Semper Fi Web Design[-1,-1] -->
<meta name="description"  content="支持向量机（support vector machine，简称SVM），在处理一些复杂的非线性问题时相比逻辑回归和神经网络要更加简洁和强大，在工业界和学术界广泛应用。 最大间隔分类器（Large Margin" />

<link rel="canonical" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html" />
<!-- /all in one seo pack -->
<link rel="alternate" type="application/rss+xml" title="雅乐网 &raquo; Andrew Ng机器学习课程笔记7——支持向量机（SVM）评论Feed" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html/feed" />
<link rel='stylesheet' id='crayon-css'  href='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta' type='text/css' media='all' />
<script type='text/javascript' src='https://lib.sinaapp.com/js/jquery/1.8.2/jquery.min.js'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"http:\/\/www.yalewoo.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"\u4f7f\u7528 %s \u590d\u5236\uff0c\u4f7f\u7528 %s \u7c98\u8d34\u3002","minimize":"\u70b9\u51fb\u5c55\u5f00\u4ee3\u7801"};
/* ]]> */
</script>
<script type='text/javascript' src='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta'></script>
<link rel='prev' title='Andrew Ng机器学习课程笔记6——机器学习应用建议和系统设计' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_6_advice_for_applying_machine_learning_and_machine_learning_system_design.html' />
<link rel='next' title='Andrew Ng机器学习课程笔记8——聚类和降维' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_8_clustering_and_dimensionality_reduction.html' />
<link rel='shortlink' href='http://www.yalewoo.com/?p=2600' />
<link rel="stylesheet" href="http://www.yalewoo.com/wp-content/plugins/wp-content-index/style.css" type="text/css" media="all" />

<!-- Start Of Script Generated By WP-PostViews -->
<script type="text/javascript">
/* <![CDATA[ */
jQuery.ajax({type:'GET',url:'http://www.yalewoo.com/wp-admin/admin-ajax.php',data:'postviews_id=2600&action=postviews',cache:false});/* ]]> */

					jQuery(document).ready(function() {
    var ajax_data = {
        action: "show_postview",
        postviews_id: 2600
    };
    $.post("http://www.yalewoo.com/wp-admin/admin-ajax.php", ajax_data,
    function(data) {
        $('.meta-view').html(data);
    });
    return false;
});					
					</script>
<!-- End Of Script Generated By WP-PostViews -->

		<script src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/jquery.lazyload.min.js" type="text/javascript"></script>
		<script type="text/javascript">
		    $(function() {
		        $("#secondary img").lazyload({
		            effect:"fadeIn"
		          });
		        });
		    $(function() {
		        $("img").lazyload({
		            effect:"fadeIn"
		          });
		        });
		</script>

<!--[if lte IE 8]><script>document.write("<p style=\"color:red;font-size:40px;\">你正在使用 Internet Explorer 的过期版本（IE6、IE7、IE8）<br/>请<a href=\"#\" style=\"color:blue;\">升级您的浏览器</a>获得更好的浏览体验。</p>");</script><![endif]-->
	
	</head><body>
<header id="topheader">
	<hgroup>
		<h1><a href = "http://www.yalewoo.com">雅乐网</a>
		</h1>
		<h2>计算机技术博客</h2>
	</hgroup>

	<div id="top_menu">
		<div class="menu-%e6%9c%80%e9%a1%b6%e7%ab%af-container"><ul id="menu-%e6%9c%80%e9%a1%b6%e7%ab%af" class="menu"><li id="menu-item-663" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-663"><a href="http://www.yalewoo.com/about">关于本站</a></li>
<li id="menu-item-662" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-662"><a href="http://www.yalewoo.com/updates">雅乐网更新记录</a></li>
<li id="menu-item-661" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-661"><a target="_blank" href="http://www.yalewoo.com/old0/">老版网站</a></li>
</ul></div>		<form method="get" id="searchform" action="http://www.yalewoo.com/">



<div>



	<input type="text" value="" name="s" id="s" size="15" />



	<input type="submit" id="searchsubmit" value="Search" />



</div>



</form>	</div>
	
	
</header>
<nav class="main_nav">
	<div class="menu-%e4%b8%bb%e8%8f%9c%e5%8d%9520171106-container"><ul id="menu-%e4%b8%bb%e8%8f%9c%e5%8d%9520171106" class="menu"><li id="menu-item-3235" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-3235"><a href="http://www.yalewoo.com/">首页</a></li>
<li id="menu-item-3237" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3237"><a href="http://www.yalewoo.com/programming">编程</a>
<ul class="sub-menu">
	<li id="menu-item-3238" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3238"><a href="http://www.yalewoo.com/programming/c_cpp">C/C++</a></li>
	<li id="menu-item-3243" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3243"><a href="http://www.yalewoo.com/programming/data_structure">数据结构</a></li>
	<li id="menu-item-3244" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3244"><a href="http://www.yalewoo.com/programming/basic_algorithm">算法</a></li>
	<li id="menu-item-3240" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3240"><a href="http://www.yalewoo.com/programming/online_judge">OJ刷题</a></li>
	<li id="menu-item-3239" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3239"><a href="http://www.yalewoo.com/programming/linux">Linux</a></li>
	<li id="menu-item-3241" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3241"><a href="http://www.yalewoo.com/programming/web">Web</a>
	<ul class="sub-menu">
		<li id="menu-item-3242" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3242"><a href="http://www.yalewoo.com/programming/web/wordpress">wordpress</a></li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3245" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor menu-item-has-children menu-item-3245"><a href="http://www.yalewoo.com/algorithm">算法</a>
<ul class="sub-menu">
	<li id="menu-item-3248" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3248"><a href="http://www.yalewoo.com/algorithm/maths">数学</a></li>
	<li id="menu-item-3246" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-3246"><a href="http://www.yalewoo.com/algorithm/ml_notes">机器学习</a></li>
	<li id="menu-item-3281" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3281"><a href="http://www.yalewoo.com/algorithm/deep_learning">深度学习</a></li>
	<li id="menu-item-3247" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3247"><a href="http://www.yalewoo.com/algorithm/python">python</a></li>
	<li id="menu-item-3253" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3253"><a href="http://www.yalewoo.com/algorithm/%e7%a4%be%e5%9b%a2%e6%a3%80%e6%b5%8b">社团检测</a></li>
</ul>
</li>
<li id="menu-item-3254" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3254"><a href="http://www.yalewoo.com/tools">工具教程</a>
<ul class="sub-menu">
	<li id="menu-item-3255" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3255"><a href="http://www.yalewoo.com/tools/git">Git/GitHub</a></li>
	<li id="menu-item-3256" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3256"><a href="http://www.yalewoo.com/tools/sublime_text">Sublime Text</a></li>
	<li id="menu-item-3257" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3257"><a href="http://www.yalewoo.com/tools/vs2013">VS2013</a></li>
	<li id="menu-item-3259" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3259"><a href="http://www.yalewoo.com/tools/browser">浏览器</a></li>
	<li id="menu-item-3258" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3258"><a href="http://www.yalewoo.com/tools/other_tools">其他工具</a></li>
</ul>
</li>
<li id="menu-item-3260" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3260"><a href="http://www.yalewoo.com/excellent_softwares">软件推荐</a>
<ul class="sub-menu">
	<li id="menu-item-3261" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3261"><a href="http://www.yalewoo.com/excellent_softwares/zip">压缩加密</a></li>
	<li id="menu-item-3262" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3262"><a href="http://www.yalewoo.com/excellent_softwares/pictools">图片工具</a></li>
	<li id="menu-item-3263" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3263"><a href="http://www.yalewoo.com/excellent_softwares/media_tools">多媒体</a></li>
	<li id="menu-item-3264" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3264"><a href="http://www.yalewoo.com/excellent_softwares/safe_software">安全清理</a></li>
	<li id="menu-item-3265" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3265"><a href="http://www.yalewoo.com/excellent_softwares/android">安卓</a></li>
	<li id="menu-item-3266" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3266"><a href="http://www.yalewoo.com/excellent_softwares/utility">实用工具</a></li>
	<li id="menu-item-3267" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3267"><a href="http://www.yalewoo.com/excellent_softwares/search_tools">搜索词典</a></li>
	<li id="menu-item-3268" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3268"><a href="http://www.yalewoo.com/excellent_softwares/efficiency_tools">效率提升</a></li>
	<li id="menu-item-3269" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3269"><a href="http://www.yalewoo.com/excellent_softwares/programming_tools">编程开发</a></li>
	<li id="menu-item-3270" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3270"><a href="http://www.yalewoo.com/excellent_softwares/internet_software">网络软件</a></li>
	<li id="menu-item-3271" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3271"><a href="http://www.yalewoo.com/excellent_softwares/edit_and_reading">阅读编辑</a></li>
</ul>
</li>
<li id="menu-item-3272" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3272"><a href="http://www.yalewoo.com/it_resource">资源</a>
<ul class="sub-menu">
	<li id="menu-item-3273" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3273"><a href="http://www.yalewoo.com/it_resource/good_websites">好网站</a></li>
	<li id="menu-item-3274" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3274"><a href="http://www.yalewoo.com/it_resource/stuff">好资料</a></li>
	<li id="menu-item-3275" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3275"><a href="http://www.yalewoo.com/it_resource/how">授人以渔</a></li>
	<li id="menu-item-3276" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3276"><a href="http://www.yalewoo.com/it_resource/ebooks-share">电子书</a></li>
</ul>
</li>
<li id="menu-item-3277" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3277"><a href="http://www.yalewoo.com/learning">我爱学习</a>
<ul class="sub-menu">
	<li id="menu-item-3278" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3278"><a href="http://www.yalewoo.com/learning/popular_science">科普</a></li>
</ul>
</li>
<li id="menu-item-3280" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3280"><a href="http://www.yalewoo.com/about">关于本站</a></li>
</ul></div></nav>
<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/dianzan.js"></script>


<div id="mbxdh">
		<div>
			
			<a href="http://www.yalewoo.com/algorithm">算法</a> &raquo; <a href="http://www.yalewoo.com/algorithm/ml_notes">机器学习</a> &raquo; Andrew Ng机器学习课程笔记7——支持向量机（SVM）		</div>
</div>
<div id="container">

		<section class="whole_article" id="article-2600">
		<article class="post-2600 post type-post status-publish format-standard hentry category-ml_notes tag-ng tag-265" id="entry">
			<h2 id="article-title">

								<span class = "title-meta-yuanchuang title-meta-ico"></span>
				
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html" title="Andrew Ng机器学习课程笔记7——支持向量机（SVM）">Andrew Ng机器学习课程笔记7——支持向量机（SVM）</a>

				


								<span class = "title-meta-huo title-meta-ico"></span>
				

			</h2>
			

            <div class="post-meta">

                <span class="meta-author meta-ico"><a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> </span>
            	                <span class="meta-time meta-ico"> 最后修改于 2017-11-18</span>
             	发表于 2016-05-08
                
                
                
                
                <span class="meta-view meta-ico">1,954</span>
                <span class="meta-comment meta-ico"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#comments">1</a></span>

                <br><br>

                <span class="meta-category meta-ico">      <a href="http://www.yalewoo.com/algorithm/ml_notes" rel="category tag">机器学习</a> </span>
                <span class="meta-category meta-ico">       <a href="http://www.yalewoo.com/tag/ng%e7%ac%94%e8%ae%b0" rel="tag">Ng笔记</a>, <a href="http://www.yalewoo.com/tag/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" rel="tag">机器学习</a> </span>

                

                
			</div>
			
			
            <div id="article-content">
				<div id="content-index" class="content-index" style="margin:0 0 10px 10px;float:right;"><span class="content-index-toctoggle">[<a id="content-index-togglelink" href="javascript:content_index_toggleToc()">目录开关</a>]</span>
<script type="text/javascript" language="javascript">
window.content_index_showTocToggle=true;function content_index_toggleToc(){var tts="显示目录";var tth="隐藏目录";if(window.content_index_showTocToggle){window.content_index_showTocToggle=false;document.getElementById("content-index-contents").style.display="block";document.getElementById("content-index-togglelink").innerHTML=tth}else{window.content_index_showTocToggle=true;document.getElementById("content-index-contents").style.display="none";document.getElementById("content-index-togglelink").innerHTML=tts}}
</script>
<ul id="content-index-contents"><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#最大间隔分类器（Large Margin Classification）" title="最大间隔分类器（Large Margin Classification）"><em>1</em><span>最大间隔分类器（Large Margin Classification）</span></a><ul class="children"><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#优化目标" title="优化目标"><em>1.1</em><span>优化目标</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#大间隔分类（Large Margin Classification）" title="大间隔分类（Large Margin Classification）"><em>1.2</em><span>大间隔分类（Large Margin Classification）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#大间隔边界背后的数学原理" title="大间隔边界背后的数学原理"><em>1.3</em><span>大间隔边界背后的数学原理</span></a></li></ul></li><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#核函数（Kernels）" title="核函数（Kernels）"><em>2</em><span>核函数（Kernels）</span></a><ul class="children"><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#高斯核函数（Gaussian Kernel）" title="高斯核函数（Gaussian Kernel）"><em>2.1</em><span>高斯核函数（Gaussian Kernel）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#细节和实际应用" title="细节和实际应用"><em>2.2</em><span>细节和实际应用</span></a></li></ul></li><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#使用SVM" title="使用SVM"><em>3</em><span>使用SVM</span></a></li></ul></div>
<p><script src="https://cdnjs.cat.net/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>支持向量机（support vector machine，简称SVM），在处理一些复杂的非线性问题时相比逻辑回归和神经网络要更加简洁和强大，在工业界和学术界广泛应用。</p>
<h3 id="最大间隔分类器（Large Margin Classification）">最大间隔分类器（Large Margin Classification）</h3>
<h4 id="优化目标">优化目标</h4>
<p>先来回顾一下逻辑回归中的优化目标，实际上对其进行修改就可以得到SVM的优化目标。</p>
<p>逻辑回归中的假说函数如下</p>
<p>$$h(x) = g(\theta^T x) = \frac{1}{1 + e^{- \theta^T x}}$$</p>
<p>为了方便下面用\(z = \theta^T x\)</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330190056.png" rel="attachment wp-att-2445"><img class="alignnone size-full wp-image-2445" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330190056.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330190056" width="628" height="297" /></a></p>
<noscript><img class="alignnone size-full wp-image-2445" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330190056.png" alt="scrn20160330190056" width="628" height="297" /></a></p></noscript>
<p>当y=1时，我们希望h(x)接近1，就要求z &gt;&gt; 0</p>
<p>当y=0时，我们希望h(x)进阶0，这要求z &lt;&lt; 0</p>
<p>再来看一下逻辑回归中的代价函数</p>
<p>$$Cost(h(x), y) = -( y log(h(x)) + (1-y) log(1-h(x)) )$$</p>
<p>$$ = &#8211; y log(\frac{1}{1 + e^{- \theta^T x}}) &#8211; (1-y) log(1-\frac{1}{1 + e^{- \theta^T x}}) $$</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936.png" rel="attachment wp-att-2601"><img class="alignnone size-full wp-image-2601" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160502150936" width="632" height="248" /></a></p>
<noscript><img class="alignnone size-full wp-image-2601" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936.png" alt="scrn20160502150936" width="632" height="248" /></a></p></noscript>
<p>上面逻辑回归中，当y=1时，如果\(\theta^T x &gt;&gt; 0\)，代价虽然很小，但不是0 ；y=1时的代价也不是准确的0。</p>
<p>SVM中修改了一下代价函数，使之由两条直线构成（图中红色）</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936-2.png" rel="attachment wp-att-2604"><img class="alignnone size-full wp-image-2604" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936-2.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160502150936" width="632" height="248" /></a></p>
<noscript><img class="alignnone size-full wp-image-2604" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936-2.png" alt="scrn20160502150936" width="632" height="248" /></a></p></noscript>
<p>这两个函数命名为cost1和cost0，下标分别对应y=1和y=0的情况。这样SVM中的代价函数如下：（注意图中横坐标\(z = \theta^T x\)）</p>
<p>$$Cost(h(x), y) = -( y cost_1(\theta^T x) + (1-y) cost_0(\theta^T x) )$$</p>
<p>回顾带正则化的逻辑回归中的代价函数</p>
<p>$$J(\theta) =\frac{1}{m} \left[ \sum_{i = 1}^{m} \left( y^{(i)} -log(h(x^{(i)})) + (1-y^{(i)}) -log\left(1-h(x^{(i)})\right) \right) \right] + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>用cost函数代替上式可以得到</p>
<p>$$J(\theta) =\frac{1}{m} \left[ \sum_{i = 1}^{m} \left( y^{(i)} cost_1(\theta^T x^{(i)}) + (1-y^{(i)}) cost_0(\theta^T x^{(i)}) \right) \right] + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>在SVM中，除了修改代价函数为cost函数外，还做了两点等价的修改：</p>
<p>1. 去掉因数\(\frac{1}{m}\)，这样对于求最值是没有影响的</p>
<p>2. 逻辑回归中用\(\lambda\)来调整正则化的程度，SVM中用C，并且放到前面一项。这相当于同时乘以\(\frac{1}{\lambda}\)，并令\(C = \frac{1}{\lambda}\)</p>
<p>这样，SVM中的代价函数如下：</p>
<p>$$J(\theta) = C \left[ \sum_{i = 1}^{m} \left( y^{(i)} cost_1(\theta^T x^{(i)}) + (1-y^{(i)}) cost_0(\theta^T x^{(i)}) \right) \right] + \frac{1}{2} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>另外，SVM中的假设也不同于逻辑回归。逻辑回归中h(x)输出的是y=1的概率，一般大于0.5认为输出1；SVM中，h(x)的输出为1或者0</p>
<p>$$h_\theta(x) =\left\{<br />
\begin{array}{c}<br />
1  \text{　　if} \theta^T x \ge 0\\<br />
0 \text{　　if} \theta^T x &lt; 0<br />
\end{array}<br />
\right.$$</p>
<p>虽然输出时，是用0来比较的；但是训练的时候，确是按照1和-1来比较。因为代价函数中，y=1时，只有z&gt;1代价才为0；y=0时，只有z&lt;-1代价才为0</p>
<h4 id="大间隔分类（Large Margin Classification）">大间隔分类（Large Margin Classification）</h4>
<p>支持向量机有的时候也被称为最大间隔分类器（Large Margin Classifier），因为SVM发现的边界与样本数据集之间有着较大的间隔。</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502154915.png" rel="attachment wp-att-2614"><img class="alignnone size-full wp-image-2614" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502154915.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160502154915" width="291" height="234" /></a></p>
<noscript><img class="alignnone size-full wp-image-2614" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502154915.png" alt="scrn20160502154915" width="291" height="234" /></a></p></noscript>
<p>上图中的黑色线边界更好，因为它和数据之间有较大的间隔。</p>
<p>这是由于，SVM的代价函数</p>
<p>$$J(\theta) = C \left[ \sum_{i = 1}^{m} \left( y^{(i)} cost_1(\theta^T x^{(i)}) + (1-y^{(i)}) cost_0(\theta^T x^{(i)}) \right) \right] + \frac{1}{2} \sum_{j=1}^{n} \theta_j^2$$</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936-2.png" rel="attachment wp-att-2604"><img class="alignnone size-full wp-image-2604" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936-2.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160502150936" width="632" height="248" /></a></p>
<noscript><img class="alignnone size-full wp-image-2604" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502150936-2.png" alt="scrn20160502150936" width="632" height="248" /></a></p></noscript>
<p>当y=1时，我们希望z &gt; 1 ，而不是z &gt; 0</p>
<p>当y=0时，我们希望z &lt; -1，而不仅仅是z &lt; 0</p>
<p>这样，SVM的要求更高，这相当于额外添加了一个安全的间距因子。</p>
<p>当参数合适时，可以保证代价函数中前一部分代价为0.那么最小化的问题就转化成了后面的一项的最小值</p>
<p>$$\frac{1}{2} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>然而，此时也有逻辑回归未正则化时遇到的问题：某些异常的值会影响边界的选择</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502155446.png" rel="attachment wp-att-2615"><img class="alignnone size-full wp-image-2615" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502155446.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160502155446" width="332" height="268" /></a></p>
<noscript><img class="alignnone size-full wp-image-2615" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160502155446.png" alt="scrn20160502155446" width="332" height="268" /></a></p></noscript>
<p>这时需要考虑正则化参数C，注意这里的C相当于逻辑回归中的\(\frac{1}{\lambda}\)</p>
<p>C 较大时，相当于λ较小，可能会导致过拟合（overfit），高方差（High variance）。</p>
<p>C 较小时，相当于λ较大，可能会导致欠拟合（underfit），高偏差（High bias）。</p>
<h4 id="大间隔边界背后的数学原理">大间隔边界背后的数学原理</h4>
<p>上面说到，参数合适的时候，只需要求下面式子的最小值</p>
<p>$$\frac{1}{2} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>所谓的参数合适，是指</p>
<p>当\(y^{(i)} = 1\)时，有 \(\theta^T x^{(i)} \ge 1\)；</p>
<p>当\(y^{(i)} = 0\)时，有 \(\theta^T x^{(i)} \le -1\)；</p>
<p>先来回顾一下向量的知识：</p>
<p>假设我们有向量\(u = \begin{pmatrix}u_1\\u_2 \end{pmatrix}\)和向量\(v = \begin{pmatrix}v_1\\v_2 \end{pmatrix}\)</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507143305.png" rel="attachment wp-att-2625"><img class="alignnone size-full wp-image-2625" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507143305.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507143305" width="339" height="201" /></a></p>
<noscript><img class="alignnone size-full wp-image-2625" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507143305.png" alt="scrn20160507143305" width="339" height="201" /></a></p></noscript>
<p>||u||表示向量u的长度，根据勾股定理，\(||u|| = \sqrt{u_1^2 + u_2^2}\)</p>
<p>再看上面要求的最小值，相当于求 \(||\theta||\)的最小值</p>
<p>再来回顾向量内积：</p>
<p>$$u \cdot v = u^T v = u_1v_1 + u_2v_2$$</p>
<p>从几何的角度，还等于v在u上的投影向量乘以||u||。（高中数学知识）</p>
<p>用向量p表示v在u上的投影向量，则有</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507143818.png" rel="attachment wp-att-2626"><img class="alignnone size-full wp-image-2626" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507143818.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507143818" width="339" height="210" /></a></p>
<noscript><img class="alignnone size-full wp-image-2626" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507143818.png" alt="scrn20160507143818" width="339" height="210" /></a></p></noscript>
<p>$$u^T v = p \cdot ||u||$$</p>
<p>再来看参数合适时的条件</p>
<p>当\(y^{(i)} = 1\)时，有 \(\theta^T x^{(i)} \ge 1\)；</p>
<p>当\(y^{(i)} = 0\)时，有 \(\theta^T x^{(i)} \le -1\)；</p>
<p>把上面的\(\theta^T x^{(i)} \) 看做 \(u^T v\)。把\(x^{(i)}\)在 \(\theta\) 上的投影向量记作\(p^{(i)}\)，则需要</p>
<p>$$\theta^T x^{(i)} = p^{(i)} ||\theta||$$</p>
<p>的绝对值尽可能的大。（大于1或者小于-1）。然而我们要最小化\(||\theta||\)，那么只能让\(p^{(i)}\)尽可能的大。</p>
<p>如果不是大间隔分类的话</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507144427.png" rel="attachment wp-att-2627"><img class="alignnone size-full wp-image-2627" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507144427.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507144427" width="308" height="192" /></a></p>
<noscript><img class="alignnone size-full wp-image-2627" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507144427.png" alt="scrn20160507144427" width="308" height="192" /></a></p></noscript>
<p>这个p向量是很小的。只有是大间隔分类的时候</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507144528.png" rel="attachment wp-att-2628"><img class="alignnone size-full wp-image-2628" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507144528.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507144528" width="401" height="259" /></a></p>
<noscript><img class="alignnone size-full wp-image-2628" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507144528.png" alt="scrn20160507144528" width="401" height="259" /></a></p></noscript>
<p>这时p是较大的，这样\(\theta\)可以小一点。</p>
<h3 id="核函数（Kernels）">核函数（Kernels）</h3>
<h4 id="高斯核函数（Gaussian Kernel）">高斯核函数（Gaussian Kernel）</h4>
<p>之前处理需要用多项式回归的时候</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507150703.png" rel="attachment wp-att-2629"><img class="alignnone size-full wp-image-2629" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507150703.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507150703" width="502" height="363" /></a></p>
<noscript><img class="alignnone size-full wp-image-2629" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507150703.png" alt="scrn20160507150703" width="502" height="363" /></a></p></noscript>
<p>假说模型可能是这样的</p>
<p>$$h(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \theta_3 x_1^2 + \theta_4 x_1x_2 + \theta_5 x_2^2$$</p>
<p>我们令 \(f_1 = x_1 + f_2 = x_2 + f_3 = x_1^2 + f_4 = x_1x_2 + f_5 = x_2^2\)，上式可以写成下面的形式</p>
<p>$$h(x) = \theta_0 + \theta_1 f_1 + \theta_2 f_2 + \theta_3 f_3 + \theta_4 f_4 + \theta_5 f_5$$</p>
<p>这里的问题是，对于f，有没有更好的选择呢？</p>
<p>这里的核函数就是一个方法。</p>
<p>选定三个地标（landmarks）。（这里是三个点，如何选取见下节）</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507151305.png" rel="attachment wp-att-2630"><img class="alignnone size-full wp-image-2630" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507151305.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507151305" width="413" height="291" /></a></p>
<noscript><img class="alignnone size-full wp-image-2630" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507151305.png" alt="scrn20160507151305" width="413" height="291" /></a></p></noscript>
<p>使用下面的公式重新得到特征</p>
<p>$$f_1 = similarity(x, l^{(1)}) = e^{- \frac{||x &#8211; l^{(1)}||^2}{2 \delta^2} }$$</p>
<p>$$f_2 = similarity(x, l^{(2)}) = e^{- \frac{||x &#8211; l^{(2)}||^2}{2 \delta^2} }$$</p>
<p>$$f_3 = similarity(x, l^{(3)}) = e^{- \frac{||x &#8211; l^{(3)}||^2}{2 \delta^2} }$$</p>
<p>这里的similarity函数就是核函数，具体的这里的这个核函数是高斯核函数。</p>
<p>高斯核函数中，e的指数部分，分子是x到l之间的距离的平方。这就有，当x接近l时，距离约为0，此时f也约为e的0次幂，大概是1；当x远离l时，距离无穷，e的负无穷次幂，大概是0。</p>
<p>\(\delta\)的选择可以影响函数变化的平缓：\(\delta\)是在分母上，它越小，整体变化越大(快)，图形越陡峭。</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507152003.png" rel="attachment wp-att-2631"><img class="alignnone size-full wp-image-2631" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507152003.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160507152003" width="794" height="468" /></a></p>
<noscript><img class="alignnone size-full wp-image-2631" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160507152003.png" alt="scrn20160507152003" width="794" height="468" /></a></p></noscript>
<p>下面看一个实例，假设是：</p>
<p>$$h(x) = \theta_0 + \theta_1 f_1 + \theta_2 f_2 + \theta_3 f_3$$</p>
<p>其中\(\theta_0 = -0.5, \theta_1 = 1, \theta_2 = 1, \theta_3 = 0\)，也就是</p>
<p>$$h(x) = -0.5 + f_1 + f_2 + 0$$</p>
<p>当上式大于0时，我们预测结果为1；小于0时，预测结果为0。</p>
<p>看下面一个例子，当某个点x靠近l1时</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160508111214.png" rel="attachment wp-att-2634"><img class="alignnone size-full wp-image-2634" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160508111214.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160508111214" width="302" height="231" /></a></p>
<noscript><img class="alignnone size-full wp-image-2634" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160508111214.png" alt="scrn20160508111214" width="302" height="231" /></a></p></noscript>
<p>x和l1的距离约为0，f1 = 1</p>
<p>x和l2，l3的距离较远，f2 = f3 = 0</p>
<p>此时有</p>
<p>$$h(x) = -0.5 + f_1 + f_2 + 0 = -0.5 + 1 + 0 + 0 = 0.5$$</p>
<p>结果大于0，预测y=1.</p>
<p>对于接近l2的点，结果也是类似的预测y=1。</p>
<p>再来看对于靠近l3的点，f1 = f2 = 0， f3 = 1</p>
<p>$$h(x) = -0.5 + 0 + 0 + 0 = -0.5$$</p>
<p>结果小于0，预测结果为0.</p>
<p>这样，这个假说的边界大致如下：</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160508111728.png" rel="attachment wp-att-2635"><img class="alignnone size-full wp-image-2635" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160508111728.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160508111728" width="368" height="238" /></a></p>
<noscript><img class="alignnone size-full wp-image-2635" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/05/scrn20160508111728.png" alt="scrn20160508111728" width="368" height="238" /></a></p></noscript>
<h4 id="细节和实际应用">细节和实际应用</h4>
<p>首先有个问题是，如何选定地标（landmarks）呢？一个简单的办法是，选择训练集中的所有点作为地标。如果训练集中有m个实例，我们就选m个地标，并且\(l^{(1)} = x^{(1)}, l^{(2)} = x^{(2)}, &#8230;, l^{(m)} = x^{(m)}\)。</p>
<p>$$f_1 = similarity(x, l^{(1)})$$</p>
<p>$$f_2 = similarity(x, l^{(2)})$$</p>
<p>$$&#8230;$$</p>
<p>额外令\(f_0 = 1\)，就可以得到f向量</p>
<p>对于训练集中的一个实例\((x^{(i)}, y^{(i)})\)</p>
<p>$$f_1^{(i)} = similarity(x^{(i)}, l^{(1)})$$</p>
<p>$$f_2^{(i)} = similarity(x^{(i)}, l^{(2)})$$</p>
<p>$$&#8230;$$</p>
<p>$$f_i^{(i)} = similarity(x^{(i)}, l^{(i)}) = e^0 = 1$$</p>
<p>$$&#8230;$$</p>
<p>$$f_m^{(i)} = similarity(x^{(i)}, l^{(m)})$$</p>
<p>这样，原本的\(x^{(i)}\)中包含n个特征，经过我们的转换后，\(f^{(i)}\)中包含了m个特征。</p>
<p>SVM中的假说：给你x，首先计算f，f包含m+1个特征。</p>
<p>当\(\theta^T f \ge 0\)时，就预测y=1.</p>
<p>那么怎么得到参数\(\theta\)呢？</p>
<p>首先看上面没有用高斯核函数时的代价函数</p>
<p>$$J(\theta) = C \left[ \sum_{i = 1}^{m} \left( y^{(i)} cost_1(\theta^T x^{(i)}) + (1-y^{(i)}) cost_0(\theta^T x^{(i)}) \right) \right] + \frac{1}{2} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>现在，需要把\(\theta^T x^{(i)}\)换成\(\theta^T f^{(i)}\)就可以了。由于x和f的维数不同，这里参数也不同啦。特别的，使用高斯核函数后，特征数和训练集实例数是一样多的。下面的n也可以换成m。</p>
<p>$$J(\theta) = C \left[ \sum_{i = 1}^{m} \left( y^{(i)} cost_1(\theta^T f^{(i)}) + (1-y^{(i)}) cost_0(\theta^T f^{(i)}) \right) \right] + \frac{1}{2} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>只要求出上面式子的最小值，就得到了参数\(\theta\)。</p>
<p>为了简化计算，一般后面一项 \(\theta^T theta\)要处理一下，变成\(\theta^T M \theta\)，这是为了提高计算效率。M矩阵的选择依赖于不同的核函数。一般软件包中都会包含这种数值优化技巧。</p>
<p>核函数也可以应用于逻辑回归，但是这时计算非常缓慢。只有在SVM中的核函数，才有这些优化方法，从而有很快的计算速度。</p>
<p>下面看一下SVM中的参数对结果的影响。</p>
<p>C较大时，相当于λ较小，可能会导致过拟合，高方差</p>
<p>C较小时，相当于λ较大，可能会导致欠拟合，高偏差</p>
<p>σ较大时，f变化更加平缓，这导致你的模型随着x的变化而缓慢变化，导致欠拟合，高偏差</p>
<p>σ较小时，f变化剧烈，导致过拟合，导致高方差</p>
<p>除了高斯核函数，还有其他核函数选择，这些和函数都应遵Mercer&#8217;s定理，以便使用计算优化技巧。不使用核函数又称为线性核函数。</p>
<h3 id="使用SVM">使用SVM</h3>
<p>如何选择逻辑回归和支持向量机呢？</p>
<p>下面是一些普遍使用的准则：</p>
<p>如果相较于m而言，n要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。</p>
<p>如果n较小，而且m大小中等，例如n在1-1000之间，而m在10-10000之间，使用带高斯核函数的支持向量机。</p>
<p>如果n较小，而m较大，例如n在1-1000之间，而m大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。</p>
<p>值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。</p>
<p>&nbsp;</p>
			</div>
		</article>

		<div class="social-main">
			<div class="post-like">
			    <a href="javascript:;" data-action="ding" data-id="2600" class="specsZan ">点赞 <span class="count">
			        1</span>
			    </a>
			</div>

			<div class="reward-button"><a href="http://www.yalewoo.com/denote" target="_blank">赏</a> 
				<span class="reward-code">
					<span class="alipay-code"> <img class="alipay-img wdp-appear" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/alipay.png"><b>支付宝打赏</b> </span> <span class="wechat-code"> <img class="wechat-img wdp-appear" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/wechatpay.png"><b>微信打赏</b> </span>
				</span>
			</div>

			<div class="post-like">
			    <a id="fenxianganniu" onClick="show_bdsharebox();">分享
			    </a>
			</div>

			<div class="bdsharebuttonbox" id="bdsharebuttonbox">
				
			</div>
			

			

		</div>
		
		<div class="reward-notice">
			<p class="">如果文章对你有帮助，欢迎点赞或打赏（金额不限）。你的打赏将全部用于支付网站服务器费用和提高网站文章质量，谢谢支持。</p>
		</div>
		
			
		

		



		

		

		<div class="article-copyright">
                			<b> 版权声明: </b>
    			<p> 本文由 <a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> 原创，商业转载请联系作者获得授权。 <br>非商业转载请注明作者 <a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> 或 <a href="http://www.yalewoo.com/" title="雅乐网" ?>雅乐网</a> ，并附带本文链接：<br><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html" title=Andrew Ng机器学习课程笔记7——支持向量机（SVM）>http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html</a></p>
						</div>

		<div class="post-navigation">
			<div class="post-previous">
				<p>上一篇：</p>
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_6_advice_for_applying_machine_learning_and_machine_learning_system_design.html" rel="prev">Andrew Ng机器学习课程笔记6——机器学习应用建议和系统设计</a>			</div>
			<div class="post-next">
				<p>下一篇：</p>
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_8_clustering_and_dimensionality_reduction.html" rel="next">Andrew Ng机器学习课程笔记8——聚类和降维</a>			</div>
		</div>


		<div class="related_posts">
			<p>与  <a href="http://www.yalewoo.com/tag/ng%e7%ac%94%e8%ae%b0" rel="tag">Ng笔记</a>, <a href="http://www.yalewoo.com/tag/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" rel="tag">机器学习</a> 相关的文章</p>
			<ul>
										<li><a rel="bookmark" href="http://www.yalewoo.com/machine_learning_practice_2_decision_tree.html" title="机器学习实战2——决策树" target="_blank">机器学习实战2——决策树</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/machine_learning_practice_1_knn.html" title="机器学习实战1——kNN算法" target="_blank">机器学习实战1——kNN算法</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_11_photo_ocr.html" title="Andrew Ng机器学习课程笔记11——图像文字识别" target="_blank">Andrew Ng机器学习课程笔记11——图像文字识别</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_10_large_scale_machine_learning.html" title="Andrew Ng机器学习课程笔记10——大规模机器学习" target="_blank">Andrew Ng机器学习课程笔记10——大规模机器学习</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_9_anomaly_detection_and_recommand_system.html" title="Andrew Ng机器学习课程笔记9——异常检测和推荐系统" target="_blank">Andrew Ng机器学习课程笔记9——异常检测和推荐系统</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_and_ex.html" title="Andrew Ng机器学习课程笔记目录" target="_blank">Andrew Ng机器学习课程笔记目录</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_8_clustering_and_dimensionality_reduction.html" title="Andrew Ng机器学习课程笔记8——聚类和降维" target="_blank">Andrew Ng机器学习课程笔记8——聚类和降维</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_6_advice_for_applying_machine_learning_and_machine_learning_system_design.html" title="Andrew Ng机器学习课程笔记6——机器学习应用建议和系统设计" target="_blank">Andrew Ng机器学习课程笔记6——机器学习应用建议和系统设计</a></li>
								</ul>
		</div>



		<div class="comments-template">
    		


<div id="comments" class="comments-area">

	
	
		<div id="respond" class="comment-respond">
		<h3 id="reply-title" class="comment-reply-title">我要评论 <small><a rel="nofollow" id="cancel-comment-reply-link" href="/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html#respond" style="display:none;">取消回复</a></small></h3>			<form action="http://www.yalewoo.com/wp-comments-post.php" method="post" id="commentform" class="comment-form">
				<p class="comment-form-comment"><textarea id="comment" name="comment" cols="45" rows="8" maxlength="65525" aria-required="true" required="required"></textarea></p>

<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/show_smilies.js"></script>

<div class="ylw_comment_toolbar">
<a class="button-insert-smilies" id="button-insert-smilies" title="插入表情" onClick="show_smilies();"></a>
</div>

<div class="ylw_smilies_box_wrapper">
<div class="ylw_smilies_box" id="ylw_smilies_box">




</div>

</div><div class="comment-name-email-url"><p class="comment-form-author"><label for="author">姓名</label><input id="author" name="author" type="text" value="" size="30" />  </p>
<p class="comment-form-email"><label for="email">邮箱</label><input id="email" name="email" type="text" value="" size="30" /> </p>
<p class="comment-form-url"><label for="url">网址</label><input id="url" name="url" type="text" value="" size="30"  /></p></div><div class='comment_yzm'>验证码*： 8 + 9 = <input type='text' name='sum' class='math_textfield'  required='required' value='' size='25' tabindex='4'><input type='hidden' name='num1' value='8'><input type='hidden' name='num2' value='9'></div><div class="comment-right"><div class="comment-submit-button">
<p class="form-submit"><input name="submit" type="submit" id="submit" class="submit" value="发表评论" /> <input type='hidden' name='comment_post_ID' value='2600' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='0' />
</p></div><div class="ylw_comment_notifyme"><input type="checkbox" name="comment_mail_notify" id="comment_mail_notify" value="comment_mail_notify" checked="checked" style="margin-left:20px;" /><label for="comment_mail_notify">有人回复时邮件通知我</label></div></div></div><div class="clear"></div>			</form>
			</div><!-- #respond -->
	
</div><!-- .comments-area -->

		</div>  


        
		
			
	</section>
	


	</div>
<footer id="footer">
      Copyright &copy;   <a title="雅乐网" href="http://www.yalewoo.com">雅乐网</a>  /<a title="自豪地采用WordPress" href="https://cn.wordpress.org" target="_blank">WordPress</a> / <a title="YLW3.0主题" href="http://www.yalewoo.com/ylw3.html" target="_blank">YLW3.0</a>  /  <a title="老薛主机" href="https://my.laoxuehost.net/aff.php?aff=2518" target="_blank">老薛主机</a>  /  <a title="七牛云存储" href="https://portal.qiniu.com/signup?code=3li1yeb2ph1ea" target="_black">七牛云存储</a>

      <div id="footer_menu">
      	<div class="menu-%e5%ba%95%e9%83%a8-container"><ul id="menu-%e5%ba%95%e9%83%a8" class="menu"><li id="menu-item-655" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-655"><a target="_blank" href="http://www.yalewoo.com/sitemap.xml">站点地图</a></li>
</ul></div>      </div>
      <div id="cnzztongji">
      	

		<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1252889774'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s5.cnzz.com/stat.php%3Fid%3D1252889774%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));</script>

    

		<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e937132d7f7e86dfb5300ce1ab2c25f7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



		</div>
</footer>

<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/backtop.js"></script>

<script type='text/javascript' src='http://www.yalewoo.com/wp-includes/js/comment-reply.min.js?ver=4.7.8'></script>



</body>
</html>
<!-- Dynamic page generated in 0.930 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2017-12-03 09:52:36 -->

<!-- Compression = gzip -->
<!-- super cache -->