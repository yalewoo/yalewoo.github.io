<!DOCTYPE html>
<html>
	<head>
		<title>
			Andrew Ng机器学习课程笔记2——线性回归  |  雅乐网		</title>
		
		<meta charset="UTF-8" />
		<meta name="renderer" content="webkit">
		<link rel="stylesheet" href="http://www.yalewoo.com/wp-content/themes/YLW3_lite/style.css" type="text/css" />
		<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://www.yalewoo.com/feed" />


				
		
<!-- All in One SEO Pack 2.3.12.1 by Michael Torbert of Semper Fi Web Design[-1,-1] -->
<meta name="description"  content="单变量线性回归 假设我们有下面的房子面积和房价的数据 面积 价格 2104 460 1416 232 1534 315 852 178 ... ... 这些已有的数据我们称之为训练集（Training" />

<link rel="canonical" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html" />
<!-- /all in one seo pack -->
<link rel="alternate" type="application/rss+xml" title="雅乐网 &raquo; Andrew Ng机器学习课程笔记2——线性回归评论Feed" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html/feed" />
<link rel='stylesheet' id='crayon-css'  href='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta' type='text/css' media='all' />
<script type='text/javascript' src='https://lib.sinaapp.com/js/jquery/1.8.2/jquery.min.js'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"http:\/\/www.yalewoo.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script type='text/javascript' src='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta'></script>
<link rel='prev' title='Andrew Ng机器学习课程笔记1——概述' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_1_introduction.html' />
<link rel='next' title='Andrew Ng机器学习课程笔记3——逻辑回归和正则化' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html' />
<link rel='shortlink' href='http://www.yalewoo.com/?p=2352' />
<link rel="stylesheet" href="http://www.yalewoo.com/wp-content/plugins/wp-content-index/style.css" type="text/css" media="all" />

<!-- Start Of Script Generated By WP-PostViews -->
<script type="text/javascript">
/* <![CDATA[ */
jQuery.ajax({type:'GET',url:'http://www.yalewoo.com/wp-admin/admin-ajax.php',data:'postviews_id=2352&action=postviews',cache:false});/* ]]> */

					jQuery(document).ready(function() {
    var ajax_data = {
        action: "show_postview",
        postviews_id: 2352
    };
    $.post("http://www.yalewoo.com/wp-admin/admin-ajax.php", ajax_data,
    function(data) {
        $('.meta-view').html(data);
    });
    return false;
});					
					</script>
<!-- End Of Script Generated By WP-PostViews -->

		<script src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/jquery.lazyload.min.js" type="text/javascript"></script>
		<script type="text/javascript">
		    $(function() {
		        $("#secondary img").lazyload({
		            effect:"fadeIn"
		          });
		        });
		    $(function() {
		        $("img").lazyload({
		            effect:"fadeIn"
		          });
		        });
		</script>

<!--[if lte IE 8]><script>document.write("<p style=\"color:red;font-size:40px;\">你正在使用 Internet Explorer 的过期版本（IE6、IE7、IE8）<br/>请<a href=\"#\" style=\"color:blue;\">升级您的浏览器</a>获得更好的浏览体验。</p>");</script><![endif]-->
	
	</head><body>
<header id="topheader">
	<hgroup>
		<h1><a href = "http://www.yalewoo.com">雅乐网</a>
		</h1>
		<h2>计算机技术博客</h2>
	</hgroup>

	<div id="top_menu">
		<div class="menu-%e6%9c%80%e9%a1%b6%e7%ab%af-container"><ul id="menu-%e6%9c%80%e9%a1%b6%e7%ab%af" class="menu"><li id="menu-item-663" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-663"><a href="http://www.yalewoo.com/about">关于本站</a></li>
<li id="menu-item-662" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-662"><a href="http://www.yalewoo.com/updates">雅乐网更新记录</a></li>
<li id="menu-item-661" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-661"><a target="_blank" href="http://www.yalewoo.com/old0/">老版网站</a></li>
</ul></div>		<form method="get" id="searchform" action="http://www.yalewoo.com/">



<div>



	<input type="text" value="" name="s" id="s" size="15" />



	<input type="submit" id="searchsubmit" value="Search" />



</div>



</form>	</div>
	
	
</header>
<nav class="main_nav">
	<div class="menu-%e4%b8%bb%e8%8f%9c%e5%8d%9520171106-container"><ul id="menu-%e4%b8%bb%e8%8f%9c%e5%8d%9520171106" class="menu"><li id="menu-item-3235" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-3235"><a href="http://www.yalewoo.com/">首页</a></li>
<li id="menu-item-3237" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3237"><a href="http://www.yalewoo.com/programming">编程</a>
<ul class="sub-menu">
	<li id="menu-item-3238" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3238"><a href="http://www.yalewoo.com/programming/c_cpp">C/C++</a></li>
	<li id="menu-item-3243" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3243"><a href="http://www.yalewoo.com/programming/data_structure">数据结构</a></li>
	<li id="menu-item-3244" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3244"><a href="http://www.yalewoo.com/programming/basic_algorithm">算法</a></li>
	<li id="menu-item-3240" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3240"><a href="http://www.yalewoo.com/programming/online_judge">OJ刷题</a></li>
	<li id="menu-item-3239" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3239"><a href="http://www.yalewoo.com/programming/linux">Linux</a></li>
	<li id="menu-item-3241" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3241"><a href="http://www.yalewoo.com/programming/web">Web</a>
	<ul class="sub-menu">
		<li id="menu-item-3242" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3242"><a href="http://www.yalewoo.com/programming/web/wordpress">wordpress</a></li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3245" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor menu-item-has-children menu-item-3245"><a href="http://www.yalewoo.com/algorithm">算法</a>
<ul class="sub-menu">
	<li id="menu-item-3248" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3248"><a href="http://www.yalewoo.com/algorithm/maths">数学</a></li>
	<li id="menu-item-3246" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-3246"><a href="http://www.yalewoo.com/algorithm/ml_notes">机器学习</a></li>
	<li id="menu-item-3281" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3281"><a href="http://www.yalewoo.com/algorithm/deep_learning">深度学习</a></li>
	<li id="menu-item-3247" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3247"><a href="http://www.yalewoo.com/algorithm/python">python</a></li>
	<li id="menu-item-3253" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3253"><a href="http://www.yalewoo.com/algorithm/%e7%a4%be%e5%9b%a2%e6%a3%80%e6%b5%8b">社团检测</a></li>
</ul>
</li>
<li id="menu-item-3254" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3254"><a href="http://www.yalewoo.com/tools">工具教程</a>
<ul class="sub-menu">
	<li id="menu-item-3255" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3255"><a href="http://www.yalewoo.com/tools/git">Git/GitHub</a></li>
	<li id="menu-item-3256" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3256"><a href="http://www.yalewoo.com/tools/sublime_text">Sublime Text</a></li>
	<li id="menu-item-3257" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3257"><a href="http://www.yalewoo.com/tools/vs2013">VS2013</a></li>
	<li id="menu-item-3259" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3259"><a href="http://www.yalewoo.com/tools/browser">浏览器</a></li>
	<li id="menu-item-3258" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3258"><a href="http://www.yalewoo.com/tools/other_tools">其他工具</a></li>
</ul>
</li>
<li id="menu-item-3260" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3260"><a href="http://www.yalewoo.com/excellent_softwares">软件推荐</a>
<ul class="sub-menu">
	<li id="menu-item-3261" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3261"><a href="http://www.yalewoo.com/excellent_softwares/zip">压缩加密</a></li>
	<li id="menu-item-3262" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3262"><a href="http://www.yalewoo.com/excellent_softwares/pictools">图片工具</a></li>
	<li id="menu-item-3263" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3263"><a href="http://www.yalewoo.com/excellent_softwares/media_tools">多媒体</a></li>
	<li id="menu-item-3264" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3264"><a href="http://www.yalewoo.com/excellent_softwares/safe_software">安全清理</a></li>
	<li id="menu-item-3265" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3265"><a href="http://www.yalewoo.com/excellent_softwares/android">安卓</a></li>
	<li id="menu-item-3266" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3266"><a href="http://www.yalewoo.com/excellent_softwares/utility">实用工具</a></li>
	<li id="menu-item-3267" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3267"><a href="http://www.yalewoo.com/excellent_softwares/search_tools">搜索词典</a></li>
	<li id="menu-item-3268" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3268"><a href="http://www.yalewoo.com/excellent_softwares/efficiency_tools">效率提升</a></li>
	<li id="menu-item-3269" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3269"><a href="http://www.yalewoo.com/excellent_softwares/programming_tools">编程开发</a></li>
	<li id="menu-item-3270" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3270"><a href="http://www.yalewoo.com/excellent_softwares/internet_software">网络软件</a></li>
	<li id="menu-item-3271" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3271"><a href="http://www.yalewoo.com/excellent_softwares/edit_and_reading">阅读编辑</a></li>
</ul>
</li>
<li id="menu-item-3272" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3272"><a href="http://www.yalewoo.com/it_resource">资源</a>
<ul class="sub-menu">
	<li id="menu-item-3273" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3273"><a href="http://www.yalewoo.com/it_resource/good_websites">好网站</a></li>
	<li id="menu-item-3274" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3274"><a href="http://www.yalewoo.com/it_resource/stuff">好资料</a></li>
	<li id="menu-item-3275" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3275"><a href="http://www.yalewoo.com/it_resource/how">授人以渔</a></li>
	<li id="menu-item-3276" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3276"><a href="http://www.yalewoo.com/it_resource/ebooks-share">电子书</a></li>
</ul>
</li>
<li id="menu-item-3277" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3277"><a href="http://www.yalewoo.com/learning">我爱学习</a>
<ul class="sub-menu">
	<li id="menu-item-3278" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3278"><a href="http://www.yalewoo.com/learning/popular_science">科普</a></li>
</ul>
</li>
<li id="menu-item-3280" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3280"><a href="http://www.yalewoo.com/about">关于本站</a></li>
</ul></div></nav>
<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/dianzan.js"></script>


<div id="mbxdh">
		<div>
			
			<a href="http://www.yalewoo.com/algorithm">算法</a> &raquo; <a href="http://www.yalewoo.com/algorithm/ml_notes">机器学习</a> &raquo; Andrew Ng机器学习课程笔记2——线性回归		</div>
</div>
<div id="container">

		<section class="whole_article" id="article-2352">
		<article class="post-2352 post type-post status-publish format-standard hentry category-ml_notes tag-ng tag-265" id="entry">
			<h2 id="article-title">

								<span class = "title-meta-yuanchuang title-meta-ico"></span>
				
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html" title="Andrew Ng机器学习课程笔记2——线性回归">Andrew Ng机器学习课程笔记2——线性回归</a>

				


								<span class = "title-meta-huo title-meta-ico"></span>
				

			</h2>
			

            <div class="post-meta">

                <span class="meta-author meta-ico"><a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> </span>
            	                <span class="meta-time meta-ico"> 最后修改于 2017-11-18</span>
             	发表于 2016-03-28
                
                
                
                
                <span class="meta-view meta-ico">2,356</span>
                <span class="meta-comment meta-ico"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#comments">2</a></span>

                <br><br>

                <span class="meta-category meta-ico">      <a href="http://www.yalewoo.com/algorithm/ml_notes" rel="category tag">机器学习</a> </span>
                <span class="meta-category meta-ico">       <a href="http://www.yalewoo.com/tag/ng%e7%ac%94%e8%ae%b0" rel="tag">Ng笔记</a>, <a href="http://www.yalewoo.com/tag/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" rel="tag">机器学习</a> </span>

                

                
			</div>
			
			
            <div id="article-content">
				<div id="content-index" class="content-index" style="margin:0 0 10px 10px;float:right;"><span class="content-index-toctoggle">[<a id="content-index-togglelink" href="javascript:content_index_toggleToc()">目录开关</a>]</span>
<script type="text/javascript" language="javascript">
window.content_index_showTocToggle=true;function content_index_toggleToc(){var tts="显示目录";var tth="隐藏目录";if(window.content_index_showTocToggle){window.content_index_showTocToggle=false;document.getElementById("content-index-contents").style.display="block";document.getElementById("content-index-togglelink").innerHTML=tth}else{window.content_index_showTocToggle=true;document.getElementById("content-index-contents").style.display="none";document.getElementById("content-index-togglelink").innerHTML=tts}}
</script>
<ul id="content-index-contents"><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#单变量线性回归" title="单变量线性回归"><em>1</em><span>单变量线性回归</span></a><ul class="children"><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#代价函数（cost function）" title="代价函数（cost function）"><em>1.1</em><span>代价函数（cost function）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#代价函数的直观理解" title="代价函数的直观理解"><em>1.2</em><span>代价函数的直观理解</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#梯度下降算法（Gradient Descent）" title="梯度下降算法（Gradient Descent）"><em>1.3</em><span>梯度下降算法（Gradient Descent）</span></a></li></ul></li><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#多变量线性回归" title="多变量线性回归"><em>2</em><span>多变量线性回归</span></a><ul class="children"><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#特征缩放（Feature Scaling）" title="特征缩放（Feature Scaling）"><em>2.1</em><span>特征缩放（Feature Scaling）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#学习率（Learning Rate）" title="学习率（Learning Rate）"><em>2.2</em><span>学习率（Learning Rate）</span></a></li></ul></li><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#多项式回归（POLYNOMIAL REGRESSION）" title="多项式回归（POLYNOMIAL REGRESSION）"><em>3</em><span>多项式回归（POLYNOMIAL REGRESSION）</span></a></li><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html#正规方程法（NORMAL EQUATION）" title="正规方程法（NORMAL EQUATION）"><em>4</em><span>正规方程法（NORMAL EQUATION）</span></a></li></ul></div>
<p><script src="https://cdnjs.cat.net/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script></p>
<h3 id="单变量线性回归">单变量线性回归</h3>
<p>假设我们有下面的房子面积和房价的数据</p>
<table class="yaletable" border="1">
<tbody>
<tr>
<th>面积</th>
<th>价格</th>
</tr>
<tr>
<td>2104</td>
<td>460</td>
</tr>
<tr>
<td>1416</td>
<td>232</td>
</tr>
<tr>
<td>1534</td>
<td>315</td>
</tr>
<tr>
<td>852</td>
<td>178</td>
</tr>
<tr>
<td>&#8230;</td>
<td>&#8230;</td>
</tr>
</tbody>
</table>
<p>这些已有的数据我们称之为训练集（Training Set）。我们通常使用字母m表示数据集中实例的个数。x表示输入变量（input variable），y表示输出变量(output/target variable)。</p>
<p>(x, y)表示数据集中的一组实例</p>
<p>\((x^{(i)}, y^{(i)})\) 表示数据集中的第i个实例。例如上表中，\((x^{(2)}, y^{(2)})\)就是第二个实例(1416, 232)</p>
<p>之后我们的算法建立模型，通过训练集的数据，来得到解决方案或者函数h（hypothesis ）。</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330210913.png"><img class="alignnone size-full wp-image-2468" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330210913.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330210913" width="414" height="344" /></a></p>
<noscript><img class="alignnone size-full wp-image-2468" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330210913.png" alt="scrn20160330210913" width="414" height="344" /></a></p></noscript>
<p>先看一下数据集的图</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330211110.png"><img class="alignnone size-full wp-image-2469" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330211110.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330211110" width="587" height="269" /></a></p>
<noscript><img class="alignnone size-full wp-image-2469" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330211110.png" alt="scrn20160330211110" width="587" height="269" /></a></p></noscript>
<p>线性回归中，我们用一条直线来拟合数据。因此可以令h为</p>
<p>$$h_{\theta_0, \theta_1}(x) = \theta_0 + \theta_1 x$$</p>
<p>其中下标 \(\theta_0, \theta_1\) 是h函数的参数（parameters），而其自变量是x。在不引起歧义的情况下，下标参数可以省略而写成h(x)。我们的目的是选择合适的参数 ，使预测最准确。</p>
<h4 id="代价函数（cost function）">代价函数（cost function）</h4>
<p>显然h(x)是关于x的一次函数，它的图形是一条直线。参数不同时，h(x)也会不同。</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330211346.png"><img class="alignnone size-full wp-image-2470" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330211346.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330211346" width="795" height="347" /></a></p>
<noscript><img class="alignnone size-full wp-image-2470" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330211346.png" alt="scrn20160330211346" width="795" height="347" /></a></p></noscript>
<p>训练集中的点到直线的垂直距离也就是预测值和实际值的差，叫做建模误差（modeling error）。</p>
<p>对第i个训练集实例来说，实际值是 \(y^{(i)}\)，预测值是 \(h(x^{(i)})\) 。它们之间的差是</p>
<p>$$h(x^{(i)}) &#8211; y^{(i)}$$</p>
<p>要评估对数据的拟合程度，很自然的想法是把每个实例的误差加起来。为了避免正负抵消，采用平方。还记得吗？我们用m表示训练集中实例个数。</p>
<p>$$\sum_{i=1}^{m} (h(x^{(i)}) &#8211; y^{(i)})^2$$</p>
<p>再把它除以m（为了表示平均误差），乘以\(\frac{1}{2}\)（为了求导后消去）（其实这对于求最值没有影响）。我们得到了代价函数</p>
<p>$$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (h(x^{(i)}) &#8211; y^{(i)})^2$$</p>
<p>这里的代价函数实际上叫做均方误差（<em>Mean Squared Error</em>, MSE），它可以反映假设h的准确度。</p>
<p>\( J(\theta_0, \theta_1) \) 越小，误差就越小。我们现在的任务就是选取\( \theta_0 和 \theta_1 \) ，来使\( J(\theta_0, \theta_1) \)最小。</p>
<h4 id="代价函数的直观理解">代价函数的直观理解</h4>
<p>先看一个简单情况：假设有m=3的训练集 (1,1), (2, 2), (3, 3) ，并且假设h(x)中的 \(\theta_0 = 0\)</p>
<p>这时我们假设</p>
<p>$$h_{\theta_1}(x) = \theta_1 x$$</p>
<p>代价函数</p>
<p>$$J(\theta_1) = \frac{1}{2*3} \sum_{i=1}^{3} (h_{\theta_1}(x^{(i)}) &#8211; y^{i})^2$$</p>
<p>当 \(\theta_1 = 1\) 时，误差是0</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234356.png"><img class="alignnone size-full wp-image-2361" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234356.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160326234356" width="912" height="501" /></a></p>
<noscript><img class="alignnone size-full wp-image-2361" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234356.png" alt="scrn20160326234356" width="912" height="501" /></a></p></noscript>
<p>当 \(\theta_1\)偏离1的时候，直线或绕原点旋转，无论顺时针还是逆时针，都会导致误差增大</p>
<p><img class="alignnone size-full wp-image-2362" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234702.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160326234702" width="891" height="503" /></p>
<noscript><img class="alignnone size-full wp-image-2362" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234702.png" alt="scrn20160326234702" width="891" height="503" /></p></noscript>
<p>由于取平方，所以误差增大的情况应该是对称的。很容易画出\(J(\theta_1)\)的图形：</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234846.png"><img class="alignnone size-full wp-image-2363" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234846.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160326234846" width="881" height="500" /></a></p>
<noscript><img class="alignnone size-full wp-image-2363" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160326234846.png" alt="scrn20160326234846" width="881" height="500" /></a></p></noscript>
<p>多维的时候，图形也是类似的：（注意到J关于\(\theta\)是二次的 它总是有局部最优 = 全局最优）</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160327182112.png"><img class="alignnone size-full wp-image-2365" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160327182112.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160327182112" width="739" height="425" /></a></p>
<noscript><img class="alignnone size-full wp-image-2365" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160327182112.png" alt="scrn20160327182112" width="739" height="425" /></a></p></noscript>
<h4 id="梯度下降算法（Gradient Descent）">梯度下降算法（Gradient Descent）</h4>
<p>梯度下降算法是通过不断迭代求最小值的方法，它不仅用于线性回归，还可以用于其他算法。</p>
<p>上面说到我们有了一个代价函数</p>
<p>$$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=0}^{m} (h(x^{(i)}) &#8211; y^{(i)})^2$$</p>
<p>通过梯度下降算法求J最小值的步骤如下：</p>
<p>1. 初始化参数 \(\theta_0, \theta_1\)</p>
<p>2. 不断改变  \(\theta_0, \theta_1\) 来缩小 \(J(\theta_0, \theta_1)\) ，直到到达一个局部最优值。</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160327182832.png"><img class="alignnone size-full wp-image-2367" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160327182832.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160327182832" width="751" height="379" /></a></p>
<noscript><img class="alignnone size-full wp-image-2367" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160327182832.png" alt="scrn20160327182832" width="751" height="379" /></a></p></noscript>
<p>那么怎么改变参数呢？从算法名字就知道，是使用梯度来改变。根据微积分中梯度的知识，梯度的方向就是函数值增长最快的方向。我们每次朝着反方向走出一步，就可以期望逐渐走到局部最小值点。更新的公式如下：</p>
<p>$$\theta_j := \theta_j &#8211; \alpha \frac{\partial }{\partial \theta_j} J(\theta_0, \theta_1)    (for j=0 and 1)$$</p>
<p>注意梯度下降算法中，每更新一次的时候，各个参数要同时更新。例如本例有2个参数\(\theta_0, \theta_1\) ，实际代码为</p>
<p>repeat until convergence {</p>
<p>$$\theta_0 := \theta_0 &#8211; \alpha \frac{\partial }{\partial \theta_0} J(\theta_0, \theta_1)$$</p>
<p>$$\theta_1 := \theta_1 -\alpha  \frac{\partial }{\partial \theta_1} J(\theta_0, \theta_1)$$</p>
<p>}</p>
<p>注意花括号内的2条语句要同步改变，如果先改变了\(\theta_0\) ，会导致\(\theta_1\)更新时使用了新的\(\theta_0\)，这样就不是梯度下降算法了。</p>
<p>应当这样实现</p>
<p>repeat until convergence {</p>
<p>$$tmp0 := \theta_0 -\alpha  \frac{\partial }{\partial \theta_0} J(\theta_0, \theta_1)$$</p>
<p>$$tmp1 := \theta_1 -\alpha  \frac{\partial }{\partial \theta_1} J(\theta_0, \theta_1)$$</p>
<p>$$\theta_0 := tmp0$$</p>
<p>$$\theta_1 :=tmp1$$</p>
<p>}</p>
<p>此处关键是要求 \(\frac{\partial }{\partial \theta_j} J(\theta_0, \theta_1)\)</p>
<p>$$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=0}^{m} (h(x^{(i)}) &#8211; y^{(i)})^2$$</p>
<p>因此</p>
<p>$$\frac{\partial }{\partial \theta_j} J(\theta_0, \theta_1)$$</p>
<p>$$ = \frac{\partial }{\partial \theta_j} \frac{1}{2m} \sum_{i=0}^{m} (h(x^{(i)}) &#8211; y^{(i)})^2$$</p>
<p>$$ = 2 \cdot \frac{1}{2m} \sum_{i=0}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) \cdot  \frac{\partial }{\partial \theta_j} (h(x^{(i)}) &#8211; y^{(i)}) \right)$$</p>
<p>h是下面的样子</p>
<p>$$h(x) = \theta_0 + \theta_1 x$$</p>
<p>可以求出后面的偏导数</p>
<p>$$\frac{\partial }{\partial \theta_0} (h(x^{(i)}) &#8211; y^{(i)}) = 1$$</p>
<p>$$\frac{\partial }{\partial \theta_1} (h(x^{(i)}) &#8211; y^{(i)}) = x$$</p>
<p>最终结果：</p>
<p>$$\frac{\partial }{\partial \theta_0} J(\theta_0, \theta_1) = \frac{1}{m} \sum_{i=0}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) \right) $$</p>
<p>$$\frac{\partial }{\partial \theta_0} J(\theta_0, \theta_1) = \frac{1}{m} \sum_{i=0}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) \cdot x\right)$$</p>
<p>最终每次迭代时更新的公式：</p>
<p>$$\theta_0 := \theta_0 -\alpha  \frac{1}{m} \sum_{i=0}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) \right) $$</p>
<p>$$\theta_1 := \theta_1 -\alpha  \frac{1}{m} \sum_{i=0}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) \cdot x\right)$$</p>
<h3 id="多变量线性回归">多变量线性回归</h3>
<p>单变量模型中房价由面积决定。实际上，房价不仅仅由面积决定，还有其他的因素。考虑的因素多余1个时，就要用到多变量模型。</p>
<p>假设我们有如下数据：</p>
<table class="yaletable" border="1">
<tbody>
<tr>
<th>面积</th>
<th>卧室数目</th>
<th>卫生间数目</th>
<th>年限</th>
<th>价格</th>
</tr>
<tr>
<td>2104</td>
<td>5</td>
<td>1</td>
<td>45</td>
<td>460</td>
</tr>
<tr>
<td>1416</td>
<td>3</td>
<td>2</td>
<td>40</td>
<td>232</td>
</tr>
<tr>
<td>1534</td>
<td>3</td>
<td>2</td>
<td>30</td>
<td>315</td>
</tr>
<tr>
<td>852</td>
<td>2</td>
<td>1</td>
<td>36</td>
<td>178</td>
</tr>
<tr>
<td>&#8230;</td>
<td>&#8230;</td>
<td>&#8230;</td>
<td>&#8230;</td>
<td>&#8230;</td>
</tr>
</tbody>
</table>
<p>我们通常用字母n表示变量（特征）个数。本例中n= 4 。</p>
<p>使用x的下标表示第几个特征</p>
<p>\(x_j^{(i)}\) 表示第i个实例中第j个特征。例如 \(x_4^{(3)}\) 表示第3个实例第4个特征，也就是年限30 。</p>
<p>多变量模型下假设h如下：</p>
<p>$$h_{(\theta_0, \theta_1, &#8230;, \theta_n)} = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + &#8230; + \theta_n x_n$$</p>
<p>上式中只有\(\theta_0\)没有乘x，为了让公式统一，我们假设\(x_0 = 1\) ，这样就有</p>
<p>$$h_{(\theta_0, \theta_1, &#8230;, \theta_n)} = \theta_0 x_0 + \theta_1 x_1 + \theta_2 x_2 + &#8230; + \theta_n x_n$$</p>
<p>$$h(x) = \sum_{i = 0}^{n} \left(  \theta_i x_i \right)$$</p>
<p>若使用向量表示</p>
<p>$$\theta = \begin{pmatrix} \theta_0 \\ \theta_1 \\ &#8230; \\ \theta_n \end{pmatrix} , x = \begin{pmatrix} x_0 \\ x_1 \\ &#8230; \\ x_n \end{pmatrix}$$</p>
<p>则有</p>
<p>$$h(x) = \theta^{T} x$$</p>
<p>多变量模型下代价函数</p>
<p>$$J(\theta_0, \theta_1, &#8230;, \theta_n) = \frac{1}{2m} \sum_{i=0}^{m} (h(x^{(i)}) &#8211; y^{(i)})^2$$</p>
<p>梯度下降更新规则(j分别从0到n为一次迭代)：</p>
<p>$$\theta_j := \theta_j &#8211; \alpha \frac{\partial }{\partial \theta_j} J(\theta_0, \theta_1, &#8230;, \theta_n) $$</p>
<p>和单变量推导类似，很容易得到最终结果</p>
<p>$$\theta_j := \theta_j -\alpha  \frac{1}{m} \sum_{i=0}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) \cdot x_j\right)$$</p>
<h4 id="特征缩放（Feature Scaling）">特征缩放（Feature Scaling）</h4>
<p>特征缩放是为了收敛地更快。多特征的时候，如果特征之间的范围不一致，比如x1的范围是0-1，x2的范围却是0-99999 。这样会导致收敛很慢。通过特征缩放让不同特征尺度大致相同</p>
<p>$$x_n = \frac{x_n &#8211; \mu_n}{s_n}$$</p>
<p>\(\mu\)是所有样本的平均值，\(s_n\)是所有样本的范围差，就是样本中最大的数值减去样本中的最小值。</p>
<p>使用特征缩放后，对新输入的数据要做相同的处理，才能保证预测结果正确。</p>
<h4 id="学习率（Learning Rate）">学习率（Learning Rate）</h4>
<p>更新的公式中的\(\alpha \)叫做学习率。它关系到每次更新的步长，如果步长太小，则收敛过程很慢；若步长太大，可能跳过最优点。</p>
<h3 id="多项式回归（POLYNOMIAL REGRESSION）">多项式回归（POLYNOMIAL REGRESSION）</h3>
<p>如果用线性不能很好地拟合数据，可以考虑多项式。例如</p>
<p>$$h(x) = \theta_0 + \theta_1 x_1 + \theta_2 x_2^2 + \theta_3 x^3$$</p>
<p>有个技巧是令</p>
<p>$$x_2 = x_2^2$$</p>
<p>$$x_3 = x_3^3$$</p>
<p>这样便转化为线性回归的问题。</p>
<h3 id="正规方程法（NORMAL EQUATION）">正规方程法（NORMAL EQUATION）</h3>
<p>该方法不需要和梯度下降算法一样迭代，而是通过数学方法直接求出令J最小的参数值。</p>
<p>令</p>
<p>$$\frac{\partial }{\partial \theta_j} J(\theta_j) = 0$$</p>
<p>可以解出</p>
<p>$$\theta = (x^Tx)^{-1} x^T y$$</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>待续。。。</p>
			</div>
		</article>

		<div class="social-main">
			<div class="post-like">
			    <a href="javascript:;" data-action="ding" data-id="2352" class="specsZan ">点赞 <span class="count">
			        1</span>
			    </a>
			</div>

			<div class="reward-button"><a href="http://www.yalewoo.com/denote" target="_blank">赏</a> 
				<span class="reward-code">
					<span class="alipay-code"> <img class="alipay-img wdp-appear" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/alipay.png"><b>支付宝打赏</b> </span> <span class="wechat-code"> <img class="wechat-img wdp-appear" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/wechatpay.png"><b>微信打赏</b> </span>
				</span>
			</div>

			<div class="post-like">
			    <a id="fenxianganniu" onClick="show_bdsharebox();">分享
			    </a>
			</div>

			<div class="bdsharebuttonbox" id="bdsharebuttonbox">
				
			</div>
			

			

		</div>
		
		<div class="reward-notice">
			<p class="">如果文章对你有帮助，欢迎点赞或打赏（金额不限）。你的打赏将全部用于支付网站服务器费用和提高网站文章质量，谢谢支持。</p>
		</div>
		
			
		

		



		

		

		<div class="article-copyright">
                			<b> 版权声明: </b>
    			<p> 本文由 <a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> 原创，商业转载请联系作者获得授权。 <br>非商业转载请注明作者 <a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> 或 <a href="http://www.yalewoo.com/" title="雅乐网" ?>雅乐网</a> ，并附带本文链接：<br><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html" title=Andrew Ng机器学习课程笔记2——线性回归>http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html</a></p>
						</div>

		<div class="post-navigation">
			<div class="post-previous">
				<p>上一篇：</p>
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_1_introduction.html" rel="prev">Andrew Ng机器学习课程笔记1——概述</a>			</div>
			<div class="post-next">
				<p>下一篇：</p>
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html" rel="next">Andrew Ng机器学习课程笔记3——逻辑回归和正则化</a>			</div>
		</div>


		<div class="related_posts">
			<p>与  <a href="http://www.yalewoo.com/tag/ng%e7%ac%94%e8%ae%b0" rel="tag">Ng笔记</a>, <a href="http://www.yalewoo.com/tag/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" rel="tag">机器学习</a> 相关的文章</p>
			<ul>
										<li><a rel="bookmark" href="http://www.yalewoo.com/machine_learning_practice_2_decision_tree.html" title="机器学习实战2——决策树" target="_blank">机器学习实战2——决策树</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/machine_learning_practice_1_knn.html" title="机器学习实战1——kNN算法" target="_blank">机器学习实战1——kNN算法</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_11_photo_ocr.html" title="Andrew Ng机器学习课程笔记11——图像文字识别" target="_blank">Andrew Ng机器学习课程笔记11——图像文字识别</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_10_large_scale_machine_learning.html" title="Andrew Ng机器学习课程笔记10——大规模机器学习" target="_blank">Andrew Ng机器学习课程笔记10——大规模机器学习</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_9_anomaly_detection_and_recommand_system.html" title="Andrew Ng机器学习课程笔记9——异常检测和推荐系统" target="_blank">Andrew Ng机器学习课程笔记9——异常检测和推荐系统</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_and_ex.html" title="Andrew Ng机器学习课程笔记目录" target="_blank">Andrew Ng机器学习课程笔记目录</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_8_clustering_and_dimensionality_reduction.html" title="Andrew Ng机器学习课程笔记8——聚类和降维" target="_blank">Andrew Ng机器学习课程笔记8——聚类和降维</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html" title="Andrew Ng机器学习课程笔记7——支持向量机（SVM）" target="_blank">Andrew Ng机器学习课程笔记7——支持向量机（SVM）</a></li>
								</ul>
		</div>



		<div class="comments-template">
    		


<div id="comments" class="comments-area">

	
	
		<div id="respond" class="comment-respond">
		<h3 id="reply-title" class="comment-reply-title">我要评论 <small><a rel="nofollow" id="cancel-comment-reply-link" href="/andrew_ng_machine_learning_notes_2_linear_regression.html#respond" style="display:none;">取消回复</a></small></h3>			<form action="http://www.yalewoo.com/wp-comments-post.php" method="post" id="commentform" class="comment-form">
				<p class="comment-form-comment"><textarea id="comment" name="comment" cols="45" rows="8" maxlength="65525" aria-required="true" required="required"></textarea></p>

<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/show_smilies.js"></script>

<div class="ylw_comment_toolbar">
<a class="button-insert-smilies" id="button-insert-smilies" title="插入表情" onClick="show_smilies();"></a>
</div>

<div class="ylw_smilies_box_wrapper">
<div class="ylw_smilies_box" id="ylw_smilies_box">




</div>

</div><div class="comment-name-email-url"><p class="comment-form-author"><label for="author">姓名</label><input id="author" name="author" type="text" value="" size="30" />  </p>
<p class="comment-form-email"><label for="email">邮箱</label><input id="email" name="email" type="text" value="" size="30" /> </p>
<p class="comment-form-url"><label for="url">网址</label><input id="url" name="url" type="text" value="" size="30"  /></p></div><div class='comment_yzm'>验证码*： 0 + 8 = <input type='text' name='sum' class='math_textfield'  required='required' value='' size='25' tabindex='4'><input type='hidden' name='num1' value='0'><input type='hidden' name='num2' value='8'></div><div class="comment-right"><div class="comment-submit-button">
<p class="form-submit"><input name="submit" type="submit" id="submit" class="submit" value="发表评论" /> <input type='hidden' name='comment_post_ID' value='2352' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='0' />
</p></div><div class="ylw_comment_notifyme"><input type="checkbox" name="comment_mail_notify" id="comment_mail_notify" value="comment_mail_notify" checked="checked" style="margin-left:20px;" /><label for="comment_mail_notify">有人回复时邮件通知我</label></div></div></div><div class="clear"></div>			</form>
			</div><!-- #respond -->
	
</div><!-- .comments-area -->

		</div>  


        
		
			
	</section>
	


	</div>
<footer id="footer">
      Copyright &copy;   <a title="雅乐网" href="http://www.yalewoo.com">雅乐网</a>  /<a title="自豪地采用WordPress" href="https://cn.wordpress.org" target="_blank">WordPress</a> / <a title="YLW3.0主题" href="http://www.yalewoo.com/ylw3.html" target="_blank">YLW3.0</a>  /  <a title="老薛主机" href="https://my.laoxuehost.net/aff.php?aff=2518" target="_blank">老薛主机</a>  /  <a title="七牛云存储" href="https://portal.qiniu.com/signup?code=3li1yeb2ph1ea" target="_black">七牛云存储</a>

      <div id="footer_menu">
      	<div class="menu-%e5%ba%95%e9%83%a8-container"><ul id="menu-%e5%ba%95%e9%83%a8" class="menu"><li id="menu-item-655" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-655"><a target="_blank" href="http://www.yalewoo.com/sitemap.xml">站点地图</a></li>
</ul></div>      </div>
      <div id="cnzztongji">
      	

		<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1252889774'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s5.cnzz.com/stat.php%3Fid%3D1252889774%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));</script>

    

		<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e937132d7f7e86dfb5300ce1ab2c25f7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



		</div>
</footer>

<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/backtop.js"></script>

<script type='text/javascript' src='http://www.yalewoo.com/wp-includes/js/comment-reply.min.js?ver=4.7.8'></script>



</body>
</html>
<!-- Dynamic page generated in 1.529 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2017-12-27 16:01:40 -->

<!-- Compression = gzip -->
<!-- super cache -->