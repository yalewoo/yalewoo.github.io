<!DOCTYPE html>
<html>
	<head>
		<title>
			Andrew Ng机器学习课程笔记3——逻辑回归和正则化  |  雅乐网		</title>
		
		<meta charset="UTF-8" />
		<meta name="renderer" content="webkit">
		<link rel="stylesheet" href="http://www.yalewoo.com/wp-content/themes/YLW3_lite/style.css" type="text/css" />
		<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://www.yalewoo.com/feed" />


				
		
<!-- All in One SEO Pack 2.3.12.1 by Michael Torbert of Semper Fi Web Design[-1,-1] -->
<meta name="description"  content="逻辑回归（Logistic Regression） 逻辑回归虽然带有“回归”两个字，实际上却是分类问题，此时要预测的值y是离散的。例如判断一封邮件是否是垃圾邮件，判断肿瘤是恶性还是良性。 先从二元逻辑回归问题开始，也就是y的值只有0和1两种取法。 假说模型 假设我们采用之前线性回归的模型 $$h(x)" />

<link rel="canonical" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html" />
<!-- /all in one seo pack -->
<link rel="alternate" type="application/rss+xml" title="雅乐网 &raquo; Andrew Ng机器学习课程笔记3——逻辑回归和正则化评论Feed" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html/feed" />
<link rel='stylesheet' id='crayon-css'  href='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta' type='text/css' media='all' />
<link rel='stylesheet' id='crayon-theme-classic-css'  href='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/themes/classic/classic.css?ver=_2.7.2_beta' type='text/css' media='all' />
<link rel='stylesheet' id='crayon-font-consolas-css'  href='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/fonts/consolas.css?ver=_2.7.2_beta' type='text/css' media='all' />
<script type='text/javascript' src='https://lib.sinaapp.com/js/jquery/1.8.2/jquery.min.js'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"http:\/\/www.yalewoo.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"\u4f7f\u7528 %s \u590d\u5236\uff0c\u4f7f\u7528 %s \u7c98\u8d34\u3002","minimize":"\u70b9\u51fb\u5c55\u5f00\u4ee3\u7801"};
/* ]]> */
</script>
<script type='text/javascript' src='http://www.yalewoo.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta'></script>
<link rel='prev' title='Andrew Ng机器学习课程笔记2——线性回归' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html' />
<link rel='next' title='Andrew Ng机器学习编程作业代码分析1——Linear Regression' href='http://www.yalewoo.com/andrew_ng_machine_learning_ex1_linear_regression.html' />
<link rel='shortlink' href='http://www.yalewoo.com/?p=2440' />
<link rel="stylesheet" href="http://www.yalewoo.com/wp-content/plugins/wp-content-index/style.css" type="text/css" media="all" />

<!-- Start Of Script Generated By WP-PostViews -->
<script type="text/javascript">
/* <![CDATA[ */
jQuery.ajax({type:'GET',url:'http://www.yalewoo.com/wp-admin/admin-ajax.php',data:'postviews_id=2440&action=postviews',cache:false});/* ]]> */

					jQuery(document).ready(function() {
    var ajax_data = {
        action: "show_postview",
        postviews_id: 2440
    };
    $.post("http://www.yalewoo.com/wp-admin/admin-ajax.php", ajax_data,
    function(data) {
        $('.meta-view').html(data);
    });
    return false;
});					
					</script>
<!-- End Of Script Generated By WP-PostViews -->

		<script src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/jquery.lazyload.min.js" type="text/javascript"></script>
		<script type="text/javascript">
		    $(function() {
		        $("#secondary img").lazyload({
		            effect:"fadeIn"
		          });
		        });
		    $(function() {
		        $("img").lazyload({
		            effect:"fadeIn"
		          });
		        });
		</script>

<!--[if lte IE 8]><script>document.write("<p style=\"color:red;font-size:40px;\">你正在使用 Internet Explorer 的过期版本（IE6、IE7、IE8）<br/>请<a href=\"#\" style=\"color:blue;\">升级您的浏览器</a>获得更好的浏览体验。</p>");</script><![endif]-->
	
	</head><body>
<header id="topheader">
	<hgroup>
		<h1><a href = "http://www.yalewoo.com">雅乐网</a>
		</h1>
		<h2>计算机技术博客</h2>
	</hgroup>

	<div id="top_menu">
		<div class="menu-%e6%9c%80%e9%a1%b6%e7%ab%af-container"><ul id="menu-%e6%9c%80%e9%a1%b6%e7%ab%af" class="menu"><li id="menu-item-663" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-663"><a href="http://www.yalewoo.com/about">关于本站</a></li>
<li id="menu-item-662" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-662"><a href="http://www.yalewoo.com/updates">雅乐网更新记录</a></li>
<li id="menu-item-661" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-661"><a target="_blank" href="http://www.yalewoo.com/old0/">老版网站</a></li>
</ul></div>		<form method="get" id="searchform" action="http://www.yalewoo.com/">



<div>



	<input type="text" value="" name="s" id="s" size="15" />



	<input type="submit" id="searchsubmit" value="Search" />



</div>



</form>	</div>
	
	
</header>
<nav class="main_nav">
	<div class="menu-%e4%b8%bb%e8%8f%9c%e5%8d%9520171106-container"><ul id="menu-%e4%b8%bb%e8%8f%9c%e5%8d%9520171106" class="menu"><li id="menu-item-3235" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-3235"><a href="http://www.yalewoo.com/">首页</a></li>
<li id="menu-item-3237" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3237"><a href="http://www.yalewoo.com/programming">编程</a>
<ul class="sub-menu">
	<li id="menu-item-3238" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3238"><a href="http://www.yalewoo.com/programming/c_cpp">C/C++</a></li>
	<li id="menu-item-3243" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3243"><a href="http://www.yalewoo.com/programming/data_structure">数据结构</a></li>
	<li id="menu-item-3244" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3244"><a href="http://www.yalewoo.com/programming/basic_algorithm">算法</a></li>
	<li id="menu-item-3240" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3240"><a href="http://www.yalewoo.com/programming/online_judge">OJ刷题</a></li>
	<li id="menu-item-3239" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3239"><a href="http://www.yalewoo.com/programming/linux">Linux</a></li>
	<li id="menu-item-3241" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3241"><a href="http://www.yalewoo.com/programming/web">Web</a>
	<ul class="sub-menu">
		<li id="menu-item-3242" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3242"><a href="http://www.yalewoo.com/programming/web/wordpress">wordpress</a></li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3245" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor menu-item-has-children menu-item-3245"><a href="http://www.yalewoo.com/algorithm">算法</a>
<ul class="sub-menu">
	<li id="menu-item-3248" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3248"><a href="http://www.yalewoo.com/algorithm/maths">数学</a></li>
	<li id="menu-item-3246" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-3246"><a href="http://www.yalewoo.com/algorithm/ml_notes">机器学习</a></li>
	<li id="menu-item-3281" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3281"><a href="http://www.yalewoo.com/algorithm/deep_learning">深度学习</a></li>
	<li id="menu-item-3247" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3247"><a href="http://www.yalewoo.com/algorithm/python">python</a></li>
	<li id="menu-item-3253" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3253"><a href="http://www.yalewoo.com/algorithm/%e7%a4%be%e5%9b%a2%e6%a3%80%e6%b5%8b">社团检测</a></li>
</ul>
</li>
<li id="menu-item-3254" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3254"><a href="http://www.yalewoo.com/tools">工具教程</a>
<ul class="sub-menu">
	<li id="menu-item-3255" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3255"><a href="http://www.yalewoo.com/tools/git">Git/GitHub</a></li>
	<li id="menu-item-3256" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3256"><a href="http://www.yalewoo.com/tools/sublime_text">Sublime Text</a></li>
	<li id="menu-item-3257" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3257"><a href="http://www.yalewoo.com/tools/vs2013">VS2013</a></li>
	<li id="menu-item-3259" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3259"><a href="http://www.yalewoo.com/tools/browser">浏览器</a></li>
	<li id="menu-item-3258" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3258"><a href="http://www.yalewoo.com/tools/other_tools">其他工具</a></li>
</ul>
</li>
<li id="menu-item-3260" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3260"><a href="http://www.yalewoo.com/excellent_softwares">软件推荐</a>
<ul class="sub-menu">
	<li id="menu-item-3261" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3261"><a href="http://www.yalewoo.com/excellent_softwares/zip">压缩加密</a></li>
	<li id="menu-item-3262" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3262"><a href="http://www.yalewoo.com/excellent_softwares/pictools">图片工具</a></li>
	<li id="menu-item-3263" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3263"><a href="http://www.yalewoo.com/excellent_softwares/media_tools">多媒体</a></li>
	<li id="menu-item-3264" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3264"><a href="http://www.yalewoo.com/excellent_softwares/safe_software">安全清理</a></li>
	<li id="menu-item-3265" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3265"><a href="http://www.yalewoo.com/excellent_softwares/android">安卓</a></li>
	<li id="menu-item-3266" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3266"><a href="http://www.yalewoo.com/excellent_softwares/utility">实用工具</a></li>
	<li id="menu-item-3267" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3267"><a href="http://www.yalewoo.com/excellent_softwares/search_tools">搜索词典</a></li>
	<li id="menu-item-3268" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3268"><a href="http://www.yalewoo.com/excellent_softwares/efficiency_tools">效率提升</a></li>
	<li id="menu-item-3269" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3269"><a href="http://www.yalewoo.com/excellent_softwares/programming_tools">编程开发</a></li>
	<li id="menu-item-3270" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3270"><a href="http://www.yalewoo.com/excellent_softwares/internet_software">网络软件</a></li>
	<li id="menu-item-3271" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3271"><a href="http://www.yalewoo.com/excellent_softwares/edit_and_reading">阅读编辑</a></li>
</ul>
</li>
<li id="menu-item-3272" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3272"><a href="http://www.yalewoo.com/it_resource">资源</a>
<ul class="sub-menu">
	<li id="menu-item-3273" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3273"><a href="http://www.yalewoo.com/it_resource/good_websites">好网站</a></li>
	<li id="menu-item-3274" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3274"><a href="http://www.yalewoo.com/it_resource/stuff">好资料</a></li>
	<li id="menu-item-3275" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3275"><a href="http://www.yalewoo.com/it_resource/how">授人以渔</a></li>
	<li id="menu-item-3276" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3276"><a href="http://www.yalewoo.com/it_resource/ebooks-share">电子书</a></li>
</ul>
</li>
<li id="menu-item-3277" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-has-children menu-item-3277"><a href="http://www.yalewoo.com/learning">我爱学习</a>
<ul class="sub-menu">
	<li id="menu-item-3278" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-3278"><a href="http://www.yalewoo.com/learning/popular_science">科普</a></li>
</ul>
</li>
<li id="menu-item-3280" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3280"><a href="http://www.yalewoo.com/about">关于本站</a></li>
</ul></div></nav>
<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/dianzan.js"></script>


<div id="mbxdh">
		<div>
			
			<a href="http://www.yalewoo.com/algorithm">算法</a> &raquo; <a href="http://www.yalewoo.com/algorithm/ml_notes">机器学习</a> &raquo; Andrew Ng机器学习课程笔记3——逻辑回归和正则化		</div>
</div>
<div id="container">

		<section class="whole_article" id="article-2440">
		<article class="post-2440 post type-post status-publish format-standard hentry category-ml_notes tag-ng tag-265" id="entry">
			<h2 id="article-title">

								<span class = "title-meta-yuanchuang title-meta-ico"></span>
				
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html" title="Andrew Ng机器学习课程笔记3——逻辑回归和正则化">Andrew Ng机器学习课程笔记3——逻辑回归和正则化</a>

				


								<span class = "title-meta-huo title-meta-ico"></span>
				

			</h2>
			

            <div class="post-meta">

                <span class="meta-author meta-ico"><a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> </span>
            	                <span class="meta-time meta-ico"> 最后修改于 2017-11-18</span>
             	发表于 2016-03-30
                
                
                
                
                <span class="meta-view meta-ico">3,358</span>
                <span class="meta-comment meta-ico"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#comments">2</a></span>

                <br><br>

                <span class="meta-category meta-ico">      <a href="http://www.yalewoo.com/algorithm/ml_notes" rel="category tag">机器学习</a> </span>
                <span class="meta-category meta-ico">       <a href="http://www.yalewoo.com/tag/ng%e7%ac%94%e8%ae%b0" rel="tag">Ng笔记</a>, <a href="http://www.yalewoo.com/tag/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" rel="tag">机器学习</a> </span>

                

                
			</div>
			
			
            <div id="article-content">
				<div id="content-index" class="content-index" style="margin:0 0 10px 10px;float:right;"><span class="content-index-toctoggle">[<a id="content-index-togglelink" href="javascript:content_index_toggleToc()">目录开关</a>]</span>
<script type="text/javascript" language="javascript">
window.content_index_showTocToggle=true;function content_index_toggleToc(){var tts="显示目录";var tth="隐藏目录";if(window.content_index_showTocToggle){window.content_index_showTocToggle=false;document.getElementById("content-index-contents").style.display="block";document.getElementById("content-index-togglelink").innerHTML=tth}else{window.content_index_showTocToggle=true;document.getElementById("content-index-contents").style.display="none";document.getElementById("content-index-togglelink").innerHTML=tts}}
</script>
<ul id="content-index-contents"><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#逻辑回归（Logistic Regression）" title="逻辑回归（Logistic Regression）"><em>1</em><span>逻辑回归（Logistic Regression）</span></a><ul class="children"><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#假说模型" title="假说模型"><em>1.1</em><span>假说模型</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#决策边界（Decision Boundary）" title="决策边界（Decision Boundary）"><em>1.2</em><span>决策边界（Decision Boundary）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#代价函数（Cost Function）" title="代价函数（Cost Function）"><em>1.3</em><span>代价函数（Cost Function）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#调用matlab中的高级算法" title="调用matlab中的高级算法"><em>1.4</em><span>调用matlab中的高级算法</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#多分类问题" title="多分类问题"><em>1.5</em><span>多分类问题</span></a></li></ul></li><li class="content-index-level-1"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#正则化（Regularization）" title="正则化（Regularization）"><em>2</em><span>正则化（Regularization）</span></a><ul class="children"><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#过拟合（Overfitting）" title="过拟合（Overfitting）"><em>2.1</em><span>过拟合（Overfitting）</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#正则化代价函数" title="正则化代价函数"><em>2.2</em><span>正则化代价函数</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#正则化线性回归" title="正则化线性回归"><em>2.3</em><span>正则化线性回归</span></a></li><li class="content-index-level-2"><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#正则化逻辑回归" title="正则化逻辑回归"><em>2.4</em><span>正则化逻辑回归</span></a></li></ul></li></ul></div>
<p><script src="https://cdnjs.cat.net/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script></p>
<h3 id="逻辑回归（Logistic Regression）">逻辑回归（Logistic Regression）</h3>
<p>逻辑回归虽然带有“回归”两个字，实际上却是分类问题，此时要预测的值y是离散的。例如判断一封邮件是否是垃圾邮件，判断肿瘤是恶性还是良性。</p>
<p>先从二元逻辑回归问题开始，也就是y的值只有0和1两种取法。</p>
<h4 id="假说模型">假说模型</h4>
<p>假设我们采用之前线性回归的模型</p>
<p>$$h(x) = \theta^T x$$</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330184641.png"><img class="alignnone size-full wp-image-2443" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330184641.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330184641" width="506" height="268" /></a></p>
<noscript><img class="alignnone size-full wp-image-2443" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330184641.png" alt="scrn20160330184641" width="506" height="268" /></a></p></noscript>
<p>线性拟合后，我们用h(x)大于0.5预测1，小于0.5预测0 。看上去此时它工作良好。但是，如果新加一个数据点</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330184827.png"><img class="alignnone size-large wp-image-2444" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330184827-1024x334.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330184827" width="1024" height="334" /></a></p>
<noscript><img class="alignnone size-large wp-image-2444" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330184827-1024x334.png" alt="scrn20160330184827" width="1024" height="334" /></a></p></noscript>
<p>这会导致预测错误。可以看出线性回归的模型不再适合这个分类问题了，因为此时h(x)的值并不是0到1之间，而可能大于1.</p>
<p>因此在逻辑回归中，我们需要引入新的模型</p>
<p>$$h(x) = g(\theta^T x)$$</p>
<p>其中的g代表逻辑函数（logistic function），其中最常用的一种叫做S 形函数（Sigmoid function），其定义如下：</p>
<p>$$g(z) = \frac{1}{1 + e^{-z}}$$</p>
<p>当z趋于负无穷时，g(z)趋向0；当z趋于正无穷时，g(z)趋向于1；当z=0时，g(z) = 0.5 。g(z)的图形大致 如下：</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330190056.png"><img class="alignnone size-full wp-image-2445" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330190056.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330190056" width="628" height="297" /></a></p>
<noscript><img class="alignnone size-full wp-image-2445" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330190056.png" alt="scrn20160330190056" width="628" height="297" /></a></p></noscript>
<p>合起来就可以得到用于逻辑回归的模型</p>
<p>$$h_\theta(x) = \frac{1}{1 + e^{- \theta^T x}}$$</p>
<p>此时h(x)给出的结果是x对应的输出y=1的概率，也就是</p>
<p>$$h(x) = P(y=1 | x; \theta)$$</p>
<p>当h(x)大于0.5时，我们预测结果为1；当h(x)小于0.5时，预测结果为0。根据上面的图形</p>
<p>\(\theta^T x &gt; 0\)时，对应h(x) &gt; 0.5，应该预测结果为1；</p>
<p>\(\theta^T x &lt; 0\)时，对应h(x) &lt; 0.5，应该预测结果为0；</p>
<h4 id="决策边界（Decision Boundary）">决策边界（Decision Boundary）</h4>
<p>模型中的分界线，将预测为1的区域和预测为0的趋于分成两部分。</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202324.png"><img class="alignnone size-full wp-image-2458" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202324.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330202324" width="726" height="321" /></a></p>
<noscript><img class="alignnone size-full wp-image-2458" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202324.png" alt="scrn20160330202324" width="726" height="321" /></a></p></noscript>
<p>&nbsp;</p>
<h4 id="代价函数（Cost Function）">代价函数（Cost Function）</h4>
<p>在线性回归模型中的代价函数是每个实例误差的平方和</p>
<p>$$J(\theta_0, \theta_1, …, \theta_n) = \frac{1}{2m} \sum_{i=0}^{m} (h(x^{(i)}) – y^{(i)})^2$$</p>
<p>但是逻辑回归中，h(x)的形式变了。如果沿用上述公式，将导致J()是一个非凸函数，不利于我们找最值。因此，代价函数也需要重新定义：</p>
<p>$$J(\theta) = \frac{1}{m} \sum_{i = 1}^{m} \left( Cost(h(x^{(i)}), y^{(i)})\right)$$</p>
<p>其中</p>
<p>$$Cost(h(x), y) = \begin{cases}<br />
-log(h(x)), &amp; \text{if $y$ = 1} \\<br />
-log(1-h(x)), &amp; \text{if $y$ = 0} \\<br />
\end{cases}$$</p>
<p>h(x)和Cost(h(x), y)之间的关系如下：</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330192223.png"><img class="alignnone size-full wp-image-2449" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330192223.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330192223" width="428" height="186" /></a></p>
<noscript><img class="alignnone size-full wp-image-2449" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330192223.png" alt="scrn20160330192223" width="428" height="186" /></a></p></noscript>
<p>&nbsp;</p>
<p>当y=1时，h(x)越接近1，Cost越小；h(x)越接近0，Cost越大。</p>
<p>当y=0时，h(x)越接近1，Cost越大；h(x)越接近0，Cost越小。</p>
<p>因此，Cost的定义是合理的，估计误差越大，代价就越大。</p>
<p>为了把Cost从两种情形合并为一种，可以写成如下的形式：</p>
<p>$$Cost(h(x), y) = -y log(h(x)) &#8211; (1-y) log(1-h(x))$$</p>
<p>代入到代价函数中得到：</p>
<p>$$J(\theta) = &#8211; \frac{1}{m} \sum_{i = 1}^{m} \left( y^{(i)} log(h(x^{(i)})) + (1-y^{(i)}) log\left(1-h(x^{(i)})\right) \right)$$</p>
<p>之后我们便可以使用梯度下降算法来求使代价函数最小的参数值了</p>
<p>$$\theta_j := \theta_j &#8211; \alpha \frac{\partial}{\partial \theta_j} J(\theta)$$</p>
<p>求导后得到<span style="color: #ff0000;">（待推导）</span></p>
<p>$$\theta_j := \theta_j &#8211; \frac{\alpha}{m} \sum_{i=1}^{m}\left(  \left(h(x^{(i)}) &#8211; y^{(i)}\right) x_j^{(i)} \right)$$</p>
<p>这看上去和线性回归中的更新规则相似，但却是不同的。因为其中的h(x)函数不一样。</p>
<p>线性回归中的假设函数</p>
<p>$$h(x) = \theta^T x$$</p>
<p>逻辑回归中的假设函数</p>
<p>$$h(x) = g(\theta^T x) = \frac{1}{1 + e^{- \theta^T x}}$$</p>
<h4 id="调用matlab中的高级算法">调用matlab中的高级算法</h4>
<p>可以调用 共轭梯度（Conjugate Gradient）,局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS)等高级算法。只需要告诉计算机 如何求 \(J(\theta)\) 和 \(\frac{\partial }{\partial \theta_j} J(\theta)\) 。</p>
<p>这些高级算法的特点：不必手动选择学习率\(\alpha\) ，收敛速度很快； 实现复杂，不过库中已经实现了。</p>
<p>下面是一个例子：</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330195258.png"><img class="alignnone size-full wp-image-2455" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330195258.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330195258" width="394" height="239" /></a></p>
<noscript><img class="alignnone size-full wp-image-2455" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330195258.png" alt="scrn20160330195258" width="394" height="239" /></a></p></noscript>
<p>我们要来求使\(J(\theta)\)最小的参数值。需要实现一个函数</p>
		<div id="crayon-5a21ff522b09b545890129" class="crayon-syntax crayon-theme-classic crayon-font-consolas crayon-os-pc print-yes notranslate" data-settings=" touchscreen minimize scroll-mouseover disable-anim wrap" style=" margin-top: 12px; margin-bottom: 12px; font-size: 20px !important; line-height: 30px !important;">
		
			<div class="crayon-plain-wrap"><textarea  class="crayon-plain print-no" data-settings="dblclick"  style="-moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4; font-size: 20px !important; line-height: 30px !important;">
function [jVal, gradient] = costFunc(theta)
    jVal = (theta(1) - 5)^2 + (theta(2) - 5)^2;
    gradient = zeros(2, 1);
    gradient(1) = 2 * (theta(1) - 5);
    gradient(2) = 2 * (theta(2) - 5);
end</textarea></div>
			<div class="crayon-main" style="">
				<table class="crayon-table">
					<tr class="crayon-row">
				<td class="crayon-nums " data-settings="show">
					<div class="crayon-nums-content" style="font-size: 20px !important; line-height: 30px !important;"><div class="crayon-num" data-line="crayon-5a21ff522b09b545890129-1">1</div><div class="crayon-num" data-line="crayon-5a21ff522b09b545890129-2">2</div><div class="crayon-num" data-line="crayon-5a21ff522b09b545890129-3">3</div><div class="crayon-num" data-line="crayon-5a21ff522b09b545890129-4">4</div><div class="crayon-num" data-line="crayon-5a21ff522b09b545890129-5">5</div><div class="crayon-num" data-line="crayon-5a21ff522b09b545890129-6">6</div></div>
				</td>
						<td class="crayon-code"><div class="crayon-pre" style="font-size: 20px !important; line-height: 30px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;"><div class="crayon-line" id="crayon-5a21ff522b09b545890129-1"><span class="crayon-st">function</span><span class="crayon-h"> </span><span class="crayon-sy">[</span><span class="crayon-i">jVal</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-r ">gradient</span><span class="crayon-sy">]</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-r">costFunc</span><span class="crayon-sy">(</span><span class="crayon-i">theta</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a21ff522b09b545890129-2"><span class="crayon-h">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="crayon-i">jVal</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">(</span><span class="crayon-r">theta</span><span class="crayon-sy">(</span><span class="crayon-cn">1</span><span class="crayon-sy">)</span><span class="crayon-h"> </span><span class="crayon-o">-</span><span class="crayon-h"> </span><span class="crayon-cn">5</span><span class="crayon-sy">)</span><span class="crayon-o">^</span><span class="crayon-cn">2</span><span class="crayon-h"> </span><span class="crayon-o">+</span><span class="crayon-h"> </span><span class="crayon-sy">(</span><span class="crayon-r">theta</span><span class="crayon-sy">(</span><span class="crayon-cn">2</span><span class="crayon-sy">)</span><span class="crayon-h"> </span><span class="crayon-o">-</span><span class="crayon-h"> </span><span class="crayon-cn">5</span><span class="crayon-sy">)</span><span class="crayon-o">^</span><span class="crayon-cn">2</span><span class="crayon-sy">;</span></div><div class="crayon-line" id="crayon-5a21ff522b09b545890129-3"><span class="crayon-h">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="crayon-r ">gradient</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-r">zeros</span><span class="crayon-sy">(</span><span class="crayon-cn">2</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">1</span><span class="crayon-sy">)</span><span class="crayon-sy">;</span></div><div class="crayon-line" id="crayon-5a21ff522b09b545890129-4"><span class="crayon-h">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="crayon-r">gradient</span><span class="crayon-sy">(</span><span class="crayon-cn">1</span><span class="crayon-sy">)</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-cn">2</span><span class="crayon-h"> </span><span class="crayon-o">*</span><span class="crayon-h"> </span><span class="crayon-sy">(</span><span class="crayon-r">theta</span><span class="crayon-sy">(</span><span class="crayon-cn">1</span><span class="crayon-sy">)</span><span class="crayon-h"> </span><span class="crayon-o">-</span><span class="crayon-h"> </span><span class="crayon-cn">5</span><span class="crayon-sy">)</span><span class="crayon-sy">;</span></div><div class="crayon-line" id="crayon-5a21ff522b09b545890129-5"><span class="crayon-h">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="crayon-r">gradient</span><span class="crayon-sy">(</span><span class="crayon-cn">2</span><span class="crayon-sy">)</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-cn">2</span><span class="crayon-h"> </span><span class="crayon-o">*</span><span class="crayon-h"> </span><span class="crayon-sy">(</span><span class="crayon-r">theta</span><span class="crayon-sy">(</span><span class="crayon-cn">2</span><span class="crayon-sy">)</span><span class="crayon-h"> </span><span class="crayon-o">-</span><span class="crayon-h"> </span><span class="crayon-cn">5</span><span class="crayon-sy">)</span><span class="crayon-sy">;</span></div><div class="crayon-line" id="crayon-5a21ff522b09b545890129-6"><span class="crayon-st">end</span></div></div></td>
					</tr>
				</table>
			</div>
		</div><p>调用</p>
		<div id="crayon-5a21ff522b0aa948271124" class="crayon-syntax crayon-theme-classic crayon-font-consolas crayon-os-pc print-yes notranslate" data-settings=" touchscreen minimize scroll-mouseover disable-anim wrap" style=" margin-top: 12px; margin-bottom: 12px; font-size: 20px !important; line-height: 30px !important;">
		
			<div class="crayon-plain-wrap"><textarea  class="crayon-plain print-no" data-settings="dblclick"  style="-moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4; font-size: 20px !important; line-height: 30px !important;">
 options = optimset('GradObj', 'on', 'MaxIter', 100);
&gt;&gt; initialTheta = zeros(2, 1);
&gt;&gt; [optTheta, functionVal, exitFlag] = fminunc(@costFunc, initialTheta, options)

Local minimum found.
Optimization completed because the size of the gradient is less than
the default value of the function tolerance.
&lt;stopping criteria details&gt;
optTheta =
     5
     5</textarea></div>
			<div class="crayon-main" style="">
				<table class="crayon-table">
					<tr class="crayon-row">
				<td class="crayon-nums " data-settings="show">
					<div class="crayon-nums-content" style="font-size: 20px !important; line-height: 30px !important;"><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-1">1</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-2">2</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-3">3</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-4">4</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-5">5</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-6">6</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-7">7</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-8">8</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-9">9</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-10">10</div><div class="crayon-num" data-line="crayon-5a21ff522b0aa948271124-11">11</div></div>
				</td>
						<td class="crayon-code"><div class="crayon-pre" style="font-size: 20px !important; line-height: 30px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;"><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-1"><span class="crayon-h"> </span><span class="crayon-i">options</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-r">optimset</span><span class="crayon-sy">(</span><span class="crayon-s">'GradObj'</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-s">'on'</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-s">'MaxIter'</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">100</span><span class="crayon-sy">)</span><span class="crayon-sy">;</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-2"><span class="crayon-o">&gt;&gt;</span><span class="crayon-h"> </span><span class="crayon-i">initialTheta</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-r">zeros</span><span class="crayon-sy">(</span><span class="crayon-cn">2</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">1</span><span class="crayon-sy">)</span><span class="crayon-sy">;</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-3"><span class="crayon-o">&gt;&gt;</span><span class="crayon-h"> </span><span class="crayon-sy">[</span><span class="crayon-i">optTheta</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-i">functionVal</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-i">exitFlag</span><span class="crayon-sy">]</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-r">fminunc</span><span class="crayon-sy">(</span><span class="crayon-sy">@</span><span class="crayon-i">costFunc</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-i">initialTheta</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-i">options</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-4">&nbsp;</div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-5"><span class="crayon-e">Local </span><span class="crayon-e">minimum </span><span class="crayon-i">found</span><span class="crayon-sy">.</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-6"><span class="crayon-e">Optimization </span><span class="crayon-e">completed </span><span class="crayon-e">because </span><span class="crayon-e">the </span><span class="crayon-r ">size</span><span class="crayon-h"> </span><span class="crayon-e">of </span><span class="crayon-e">the </span><span class="crayon-r ">gradient</span><span class="crayon-h"> </span><span class="crayon-st">is</span><span class="crayon-h"> </span><span class="crayon-e">less </span><span class="crayon-e">than</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-7"><span class="crayon-e">the </span><span class="crayon-e">default </span><span class="crayon-e">value </span><span class="crayon-e">of </span><span class="crayon-e">the </span><span class="crayon-st">function</span><span class="crayon-h"> </span><span class="crayon-i">tolerance</span><span class="crayon-sy">.</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-8"><span class="crayon-o">&lt;</span><span class="crayon-e">stopping </span><span class="crayon-e">criteria </span><span class="crayon-i">details</span><span class="crayon-o">&gt;</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-9"><span class="crayon-i">optTheta</span><span class="crayon-h"> </span><span class="crayon-o">=</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-10"><span class="crayon-h">&nbsp;&nbsp;&nbsp;&nbsp; </span><span class="crayon-cn">5</span></div><div class="crayon-line" id="crayon-5a21ff522b0aa948271124-11"><span class="crayon-h">&nbsp;&nbsp;&nbsp;&nbsp; </span><span class="crayon-cn">5</span></div></div></td>
					</tr>
				</table>
			</div>
		</div><p></p>
<h4 id="多分类问题">多分类问题</h4>
<p>多分类问题中的y输出多余2个值，一种可能的情况如下：</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330200140.png"><img class="alignnone size-full wp-image-2456" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330200140.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330200140" width="209" height="229" /></a></p>
<noscript><img class="alignnone size-full wp-image-2456" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330200140.png" alt="scrn20160330200140" width="209" height="229" /></a></p></noscript>
<p>使用一对多（One-vs-All）的方法可以解决这个问题。在一对多方法中，每次我们把数据分为y=某个和y=其他。</p>
<p>例如，先分成y=1和其他两部分，得到 \(h^{(1)}(x)\)</p>
<p>类似，y=2时可以得到 \(h^{(2)}(x)\)</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330203213.png"><img class="alignnone size-full wp-image-2461" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330203213.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330203213" width="784" height="434" /></a></p>
<noscript><img class="alignnone size-full wp-image-2461" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330203213.png" alt="scrn20160330203213" width="784" height="434" /></a></p></noscript>
<p>最后，我们得到一系列假说</p>
<p>$$h^{(i)}(x)$$</p>
<p>在多分类问题时，我们把每个假说函数运行一遍，求出其中最大的概率。</p>
<h3 id="正则化（Regularization）">正则化（Regularization）</h3>
<h4 id="过拟合（Overfitting）">过拟合（Overfitting）</h4>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202647.png"><img class="alignnone size-full wp-image-2459" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202647.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330202647" width="757" height="189" /></a></p>
<noscript><img class="alignnone size-full wp-image-2459" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202647.png" alt="scrn20160330202647" width="757" height="189" /></a></p></noscript>
<p>第一个用线性来拟合，显然不够准确，这称为欠拟合。</p>
<p>第二个看上去刚刚好。</p>
<p>第三个用过高次数的多项式，虽然完美拟合了训练集中的每个数据，但显然预测新数据时并不可靠。这称为过拟合。</p>
<p>分类问题中也有类似的问题</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202941.png"><img class="alignnone size-full wp-image-2460" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202941.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330202941" width="791" height="298" /></a></p>
<noscript><img class="alignnone size-full wp-image-2460" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330202941.png" alt="scrn20160330202941" width="791" height="298" /></a></p></noscript>
<h4 id="正则化代价函数">正则化代价函数</h4>
<p>上面回归问题中过拟合的模型是</p>
<p>$$h(x) = \theta_0 + \theta_1 x1 + \theta_2 x_2^2 + \theta_3 x_3^3 + \theta_4 x_4^4$$</p>
<p>如果减少 \(\theta_3\) 和 \(\theta_4\)的值，可以考虑修改代价函数，给它们添加一些惩罚。修改后的代价函数如下：</p>
<p>$$J(\theta) = \frac{1}{2m} \left( \sum_{i=1}^{m}  (h(x^{(i)}) &#8211; y^{(i)})^2 + 999\theta_3^2 + 999\theta_4^2 \right)$$</p>
<p>这样会使\(\theta_3\) 和 \(\theta_4\)的值减小很多。</p>
<p>假设我们有很多特征，不知道要缩小哪一个，可以采用下面的办法</p>
<p>$$J(\theta) = \frac{1}{2m} \left( \sum_{i=1}^{m}  (h(x^{(i)}) &#8211; y^{(i)})^2 + \lambda \sum_{j=1}^{n} \theta_j^2 \right)$$</p>
<p>根据惯例，我们不对\(\theta_0\)进行惩罚。</p>
<p>其中 \(\lambda\)又叫做正则化参数（Regularization Parameter）。如果正则化参数太大，则会把所有参数最小化，导致近似直线，造成欠拟合。</p>
<h4 id="正则化线性回归">正则化线性回归</h4>
<p>代价函数</p>
<p>$$J(\theta) = \frac{1}{2m} \left( \sum_{i=1}^{m}  (h(x^{(i)}) &#8211; y^{(i)})^2 + \lambda \sum_{j=1}^{n} \theta_j^2 \right)$$</p>
<p>更新规则</p>
<p>$$\theta_0 := \theta_0 &#8211; \alpha \frac{1}{m} \sum_{i=1}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) x_0^{(i)} \right)$$</p>
<p>$$\theta_j := \theta_j &#8211; \alpha  \left( \frac{1}{m} \sum_{i=1}^{m}  (h(x^{(i)}) &#8211; y^{(i)}) x_0^{(i)}  + \frac{\lambda}{m} \theta_j \right) , \text{for j = 1, 2, &#8230; , n}$$</p>
<p>把上式变形一下</p>
<p>$$\theta_j := \theta_j(1 &#8211; \alpha \frac{\lambda}{m}) &#8211; \alpha \frac{1}{m} \sum_{i=1}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) x_j^{(i)} \right)$$</p>
<p>对比不正则化的线性回归，正则化线性回归的梯度下降中，每\(\theta\)的因数从1变为\(1 &#8211; \alpha \frac{\lambda}{m}\)，因此\(\theta\)要额外缩小了一点。</p>
<p>使用正规方程也可以求解正则化线性回归问题，公式是</p>
<p><a target="_blank" href="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330210145.png"><img class="alignnone size-full wp-image-2463" data-original="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330210145.png" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" alt="scrn20160330210145" width="524" height="130" /></a></p>
<noscript><img class="alignnone size-full wp-image-2463" src="http://7d9rd6.com1.z0.glb.clouddn.com/wp-content/uploads/2016/03/scrn20160330210145.png" alt="scrn20160330210145" width="524" height="130" /></a></p></noscript>
<h4 id="正则化逻辑回归">正则化逻辑回归</h4>
<p>代价函数</p>
<p>$$J(\theta) = &#8211; \left[ \frac{1}{m} \sum_{i = 1}^{m} \left( y^{(i)} log(h(x^{(i)})) + (1-y^{(i)}) log\left(1-h(x^{(i)})\right) \right) \right] + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^2$$</p>
<p>通过求导得出的梯度下降算法更新规则</p>
<p>$$\theta_0 := \theta_0 &#8211; \alpha \frac{1}{m} \sum_{i=1}^{m} \left( (h(x^{(i)}) &#8211; y^{(i)}) x_0^{(i)} \right)$$</p>
<p>$$\theta_j := \theta_j &#8211; \alpha \left(\frac{1}{m} \sum_{i=1}^{m}  (h(x^{(i)}) &#8211; y^{(i)}) x_j^{(i)} + \frac{\lambda}{m} \theta_j \right) , \text{for j = 1, 2, &#8230; , n}$$</p>
<p>这看上去和线性回归一样，但是h(x)是不同的。</p>
<p>仍然可以使用fminuc等函数来求解，只需修改参数的更新规则。</p>
<p>&nbsp;</p>
			</div>
		</article>

		<div class="social-main">
			<div class="post-like">
			    <a href="javascript:;" data-action="ding" data-id="2440" class="specsZan ">点赞 <span class="count">
			        0</span>
			    </a>
			</div>

			<div class="reward-button"><a href="http://www.yalewoo.com/denote" target="_blank">赏</a> 
				<span class="reward-code">
					<span class="alipay-code"> <img class="alipay-img wdp-appear" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/alipay.png"><b>支付宝打赏</b> </span> <span class="wechat-code"> <img class="wechat-img wdp-appear" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/wechatpay.png"><b>微信打赏</b> </span>
				</span>
			</div>

			<div class="post-like">
			    <a id="fenxianganniu" onClick="show_bdsharebox();">分享
			    </a>
			</div>

			<div class="bdsharebuttonbox" id="bdsharebuttonbox">
				
			</div>
			

			

		</div>
		
		<div class="reward-notice">
			<p class="">如果文章对你有帮助，欢迎点赞或打赏（金额不限）。你的打赏将全部用于支付网站服务器费用和提高网站文章质量，谢谢支持。</p>
		</div>
		
			
		

		



		

		

		<div class="article-copyright">
                			<b> 版权声明: </b>
    			<p> 本文由 <a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> 原创，商业转载请联系作者获得授权。 <br>非商业转载请注明作者 <a href="http://www.yalewoo.com/author/yalewoo" title="由yalewoo发布" rel="author">yalewoo</a> 或 <a href="http://www.yalewoo.com/" title="雅乐网" ?>雅乐网</a> ，并附带本文链接：<br><a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html" title=Andrew Ng机器学习课程笔记3——逻辑回归和正则化>http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html</a></p>
						</div>

		<div class="post-navigation">
			<div class="post-previous">
				<p>上一篇：</p>
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_2_linear_regression.html" rel="prev">Andrew Ng机器学习课程笔记2——线性回归</a>			</div>
			<div class="post-next">
				<p>下一篇：</p>
				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_ex1_linear_regression.html" rel="next">Andrew Ng机器学习编程作业代码分析1——Linear Regression</a>			</div>
		</div>


		<div class="related_posts">
			<p>与  <a href="http://www.yalewoo.com/tag/ng%e7%ac%94%e8%ae%b0" rel="tag">Ng笔记</a>, <a href="http://www.yalewoo.com/tag/%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0" rel="tag">机器学习</a> 相关的文章</p>
			<ul>
										<li><a rel="bookmark" href="http://www.yalewoo.com/machine_learning_practice_2_decision_tree.html" title="机器学习实战2——决策树" target="_blank">机器学习实战2——决策树</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/machine_learning_practice_1_knn.html" title="机器学习实战1——kNN算法" target="_blank">机器学习实战1——kNN算法</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_11_photo_ocr.html" title="Andrew Ng机器学习课程笔记11——图像文字识别" target="_blank">Andrew Ng机器学习课程笔记11——图像文字识别</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_10_large_scale_machine_learning.html" title="Andrew Ng机器学习课程笔记10——大规模机器学习" target="_blank">Andrew Ng机器学习课程笔记10——大规模机器学习</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_9_anomaly_detection_and_recommand_system.html" title="Andrew Ng机器学习课程笔记9——异常检测和推荐系统" target="_blank">Andrew Ng机器学习课程笔记9——异常检测和推荐系统</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_and_ex.html" title="Andrew Ng机器学习课程笔记目录" target="_blank">Andrew Ng机器学习课程笔记目录</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_8_clustering_and_dimensionality_reduction.html" title="Andrew Ng机器学习课程笔记8——聚类和降维" target="_blank">Andrew Ng机器学习课程笔记8——聚类和降维</a></li>
											<li><a rel="bookmark" href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_7_support_vecrot_machines.html" title="Andrew Ng机器学习课程笔记7——支持向量机（SVM）" target="_blank">Andrew Ng机器学习课程笔记7——支持向量机（SVM）</a></li>
								</ul>
		</div>



		<div class="comments-template">
    		


<div id="comments" class="comments-area">

			<h3 class="comments-title">
		文章《Andrew Ng机器学习课程笔记3——逻辑回归和正则化》共有2条评论：
		</h3>

		
		<ol class="comment-list">
				<li class="comment even thread-even depth-1" id="li-comment-330">
		<div id="comment-330" class="comment-one">
			<div class="comment-author-avatar">
  			<img alt='' data-original="http://0.gravatar.com/avatar/?s=64&#038;d=identicon&#038;r=g" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" srcset='http://2.gravatar.com/avatar/?s=128&amp;d=identicon&amp;r=g 2x' class='avatar avatar-64 photo avatar-default' height='64' width='64' />
<noscript><img alt='' src='http://0.gravatar.com/avatar/?s=64&#038;d=identicon&#038;r=g' srcset='http://2.gravatar.com/avatar/?s=128&amp;d=identicon&amp;r=g 2x' class='avatar avatar-64 photo avatar-default' height='64' width='64' /></noscript>			</div>
						<div class="comment-body">
				<div class="comment-author-name">
  				dgs   				</div>
  				
  				<p>不是归一化线性/逻辑回归, 是正则化线性/逻辑回归.  归一化是mean normalization, 正则化是regularization. 两个不是一回事</p>
				
				<div class="comment-meta">

    				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#comment-330"><time datetime="2017-03-01T12:11:27+00:00">2017年3月1日 12:11</time></a>

				
								
				<span class="reply">
					<a rel='nofollow' class='comment-reply-link' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html?replytocom=330#respond' onclick='return addComment.moveForm( "comment-330", "330", "respond", "2440" )' aria-label='回复给dgs'>回复</a>				</span>
				</div>
			</div>
		</div>
	<ul class="children">
	<li class="comment byuser comment-author-yalewoo bypostauthor odd alt depth-2" id="li-comment-331">
		<div id="comment-331" class="comment-one">
			<div class="comment-author-avatar">
  			<img alt='' data-original="http://0.gravatar.com/avatar/62e19307736b9ce9073ce4c5f76e5407?s=64&#038;d=identicon&#038;r=g" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/img/loading.gif" srcset='http://0.gravatar.com/avatar/62e19307736b9ce9073ce4c5f76e5407?s=128&amp;d=identicon&amp;r=g 2x' class='avatar avatar-64 photo' height='64' width='64' />
<noscript><img alt='' src='http://0.gravatar.com/avatar/62e19307736b9ce9073ce4c5f76e5407?s=64&#038;d=identicon&#038;r=g' srcset='http://0.gravatar.com/avatar/62e19307736b9ce9073ce4c5f76e5407?s=128&amp;d=identicon&amp;r=g 2x' class='avatar avatar-64 photo' height='64' width='64' /></noscript>			</div>
						<div class="comment-body">
				<div class="comment-author-name">
  				<a href='http://www.yalewoo.com/'  target='_blank'>yalewoo</a> <span class="comment-author-is-bloger"> 作者</span>  				</div>
  				
  				<p>对的对的 谢谢指正 <img src="http://img.t.sinajs.cn/t35/style/images/common/face/ext/normal/d8/good_org.gif" />  已经修改了</p>
				
				<div class="comment-meta">

    				<a href="http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#comment-331"><time datetime="2017-03-01T12:56:42+00:00">2017年3月1日 12:56</time></a>

				
								
				<span class="reply">
					<a rel='nofollow' class='comment-reply-link' href='http://www.yalewoo.com/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html?replytocom=331#respond' onclick='return addComment.moveForm( "comment-331", "331", "respond", "2440" )' aria-label='回复给yalewoo'>回复</a>				</span>
				</div>
			</div>
		</div>
	</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		
	
	
		<div id="respond" class="comment-respond">
		<h3 id="reply-title" class="comment-reply-title">我要评论 <small><a rel="nofollow" id="cancel-comment-reply-link" href="/andrew_ng_machine_learning_notes_3_logistic_regression_and_regularization.html#respond" style="display:none;">取消回复</a></small></h3>			<form action="http://www.yalewoo.com/wp-comments-post.php" method="post" id="commentform" class="comment-form">
				<p class="comment-form-comment"><textarea id="comment" name="comment" cols="45" rows="8" maxlength="65525" aria-required="true" required="required"></textarea></p>

<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/show_smilies.js"></script>

<div class="ylw_comment_toolbar">
<a class="button-insert-smilies" id="button-insert-smilies" title="插入表情" onClick="show_smilies();"></a>
</div>

<div class="ylw_smilies_box_wrapper">
<div class="ylw_smilies_box" id="ylw_smilies_box">




</div>

</div><div class="comment-name-email-url"><p class="comment-form-author"><label for="author">姓名</label><input id="author" name="author" type="text" value="" size="30" />  </p>
<p class="comment-form-email"><label for="email">邮箱</label><input id="email" name="email" type="text" value="" size="30" /> </p>
<p class="comment-form-url"><label for="url">网址</label><input id="url" name="url" type="text" value="" size="30"  /></p></div><div class='comment_yzm'>验证码*： 9 + 6 = <input type='text' name='sum' class='math_textfield'  required='required' value='' size='25' tabindex='4'><input type='hidden' name='num1' value='9'><input type='hidden' name='num2' value='6'></div><div class="comment-right"><div class="comment-submit-button">
<p class="form-submit"><input name="submit" type="submit" id="submit" class="submit" value="发表评论" /> <input type='hidden' name='comment_post_ID' value='2440' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='0' />
</p></div><div class="ylw_comment_notifyme"><input type="checkbox" name="comment_mail_notify" id="comment_mail_notify" value="comment_mail_notify" checked="checked" style="margin-left:20px;" /><label for="comment_mail_notify">有人回复时邮件通知我</label></div></div></div><div class="clear"></div>			</form>
			</div><!-- #respond -->
	
</div><!-- .comments-area -->

		</div>  


        
		
			
	</section>
	


	</div>
<footer id="footer">
      Copyright &copy;   <a title="雅乐网" href="http://www.yalewoo.com">雅乐网</a>  /<a title="自豪地采用WordPress" href="https://cn.wordpress.org" target="_blank">WordPress</a> / <a title="YLW3.0主题" href="http://www.yalewoo.com/ylw3.html" target="_blank">YLW3.0</a>  /  <a title="老薛主机" href="https://my.laoxuehost.net/aff.php?aff=2518" target="_blank">老薛主机</a>  /  <a title="七牛云存储" href="https://portal.qiniu.com/signup?code=3li1yeb2ph1ea" target="_black">七牛云存储</a>

      <div id="footer_menu">
      	<div class="menu-%e5%ba%95%e9%83%a8-container"><ul id="menu-%e5%ba%95%e9%83%a8" class="menu"><li id="menu-item-655" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-655"><a target="_blank" href="http://www.yalewoo.com/sitemap.xml">站点地图</a></li>
</ul></div>      </div>
      <div id="cnzztongji">
      	

		<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1252889774'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s5.cnzz.com/stat.php%3Fid%3D1252889774%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));</script>

    

		<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e937132d7f7e86dfb5300ce1ab2c25f7";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



		</div>
</footer>

<script type="text/javascript" src="http://www.yalewoo.com/wp-content/themes/YLW3_lite/js/backtop.js"></script>

<script type='text/javascript' src='http://www.yalewoo.com/wp-includes/js/comment-reply.min.js?ver=4.7.8'></script>



</body>
</html>
<!-- Dynamic page generated in 1.301 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2017-12-02 09:18:10 -->

<!-- Compression = gzip -->
<!-- super cache -->